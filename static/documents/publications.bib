@inproceedings{zhu2024online,
  title={Online Learning in Betting Markets: Profit versus Prediction},
  author={Zhu, Haiqing and Soen, Alexander and Cheung, Yun Kuen and Xie, Lexing},
  booktitle={Forty-first International Conference on Machine Learning (ICML '24)}, 
  year         = {2024},
  abstract     = {We examine two types of binary betting markets, whose primary goal is for profit (such as sports gambling) or to gain information (such as prediction markets). We articulate the interplay between belief and price-setting to analyse both types of markets, and show that the goals of maximising bookmaker profit and eliciting information are fundamentally incompatible. A key insight is that profit hinges on the deviation between (the distribution of) bettor and true beliefs, and that heavier tails in bettor belief distribution imply higher profit. Our algorithmic contribution is to introduce online learning methods for price-setting. Traditionally bookmakers update their prices rather infrequently, we present two algorithms that guide price updates upon seeing each bet, assuming very little of bettor belief distributions. The online pricing algorithm achieves stochastic regret of $O(\sqrt{T})$ against the worst local maximum, or $O(T log \sqrt{T} )$ with high probability against the global maximum under fair odds. More broadly, the inherent trade-off between profit and information-seeking in binary betting may inspire new understandings of large-scale multi-agent behaviour.}, 
  url_abstract = {https://arxiv.org/abs/2406.04062},
  url_paper    = {https://arxiv.org/pdf/2406.04062}
}

@inproceedings{nguyen2024icwsm,
  author       = {Nguyen, Tuan Dung and Chen, Ziyu and Carroll, Nicholas George and Tran, Alasdair and Klein, Colin and Xie, Lexing},
  title        = {Measuring Moral Dimensions in Social Media with {Mformer}},
  booktitle    = {International AAAI Conference on Web and Social Media (ICWSM '24)},
  year         = {2024},
  abstract     = {The ever-growing textual records of contemporary social issues, often discussed online with moral rhetoric, present both an opportunity and a challenge for studying how moral concerns are debated in real life. Moral foundations theory is a taxonomy of intuitions widely used in data-driven analyses of online content, but current computational tools to detect moral foundations suffer from the incompleteness and fragility of their lexicons and from poor generalization across data domains. In this paper, we fine-tune a large language model to measure moral foundations in text based on datasets covering news media and long- and short-form online discussions. The resulting model, called Mformer, outperforms existing approaches on the same domains by 4--12% in AUC and further generalizes well to four commonly used moral text datasets, improving by up to 17% in AUC. We present case studies using Mformer to analyze everyday moral dilemmas on Reddit and controversies on Twitter, showing that moral foundations can meaningfully describe people's stance on social issues and such variations are topic-dependent. Pre-trained model and datasets are released publicly. We posit that Mformer will help the research community quantify moral dimensions for a range of tasks and data domains, and eventually contribute to the understanding of moral situations faced by humans and machines.},
  url_abstract = {https://arxiv.org/abs/2311.10219},
  url_paper    = {https://arxiv.org/pdf/2311.10219}
}


@inproceedings{yang2023shape,
  address      = {Minneapolis, MN, USA},
  author       = {Cai Yang and Lexing Xie and Siqi Wu},
  booktitle    = {ACM Conference on Computer-Supported Cooperative Work and Social Computing (CSCW '23)},
  title        = {The Shapes of the Fourth Estate During the Pandemic: Profiling COVID-19 News Consumption in Eight Countries},
  year         = {2023},
  abstract     = {News media is often referred to as the Fourth Estate, a recognition of its political power. New understandings of how media shape political beliefs and influence collective behaviors are urgently needed in an era when public opinion polls do not necessarily reflect election results and users influence each other in real-time under algorithm-mediated content personalization. In this work, we measure not only the average but also the distribution of audience political leanings for different media across different countries. The methodological components of these new measures include a high-fidelity COVID-19 tweet dataset; high-precision user geolocation extraction; and user political leaning estimated from the within-country retweet networks involving local politicians. We focus on geolocated users from eight countries, profile user leaning distribution for each country, and analyze bridging users who have interactions across multiple countries. Except for France and Turkey, we observe consistent bi-modal user leaning distributions in the other six countries, and find that cross-country retweeting behaviors do not oscillate across the partisan divide. More importantly, this study contributes a new set of media bias estimates by averaging the leaning scores of users who share the URLs from media domains. Through two validations, we find that the new average audience leaning scores strongly correlate with existing media bias scores. Lastly, we profile the COVID-19 news consumption by examining the audience leaning distribution for top media in each country, and for selected media across all countries. Those analyses help answer questions such as: Does center media Reuters have a more balanced audience base than partisan media CNN in the US? Does far-right media Breitbart attract any left-leaning readers in any countries? Does CNN reach a more balanced audience base in the US than in the UK?},
  url_abstract = {https://arxiv.org/abs/2308.01453},
  url_paper    = {https://arxiv.org/pdf/2308.01453},
  url_code     = {https://github.com/computationalmedia/media_landscape},
}


@inproceedings{tran2023factorized,
  title={Factorized fourier neural operators},
  author={Tran, Alasdair and Mathews, Alexander and Xie, Lexing and Ong, Cheng Soon},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023}, 
  url_abstract = {https://openreview.net/forum?id=tmIiMPl4IPa},
  url_paper = {https://arxiv.org/pdf/2111.13802},
  url_code = {https://github.com/alasdairtran/fourierflow}, 
  abstract  = {We propose the Factorized Fourier Neural Operator (F-FNO), a learning-based approach for simulating partial differential equations (PDEs). Starting from a recently proposed Fourier representation of flow fields, the F-FNO bridges the performance gap between pure machine learning approaches to that of the best numerical or hybrid solvers. This is achieved with new representations – separable spectral layers and improved residual connections – and a combination of training strategies such as the Markov assumption, Gaussian noise, and cosine learning rate decay. On several challenging benchmark PDEs on regular grids, structured meshes, and point clouds, the F-FNO can scale to deeper networks and outperform both the FNO and the geo-FNO, reducing the error by 83% on the Navier-Stokes problem, 31% on the elasticity problem, 57% on the airfoil flow problem, and 60% on the plastic forging problem. Compared to the state-of-the-art pseudo-spectral method, the F-FNO can take a step size that is an order of magnitude larger in time and achieve an order of magnitude speedup to produce the same solution quality.}
}

@inproceedings{Zhu2023Stability,
  title={Stability and Efficiency of Personalised Cultural Markets},
  author={Haiqing Zhu and Yun Kuen Cheung and Lexing Xie},
  booktitle = {The Web Conference 2023},
  year      = {2023},
  url_abstract = {https://arxiv.org/abs/2302.06226},
  url_paper = {https://arxiv.org/pdf/2302.06226.pdf},
  abstract  = {This work is concerned with the dynamics of online cultural markets, namely, attention allocation of many users on a set of digital goods with infinite supply. Such dynamic is important in shaping processes and outcomes in society, from trending items in entertainment, collective knowledge creation, to election outcomes. The outcomes of online cultural markets are susceptible to intricate social influence dynamics, particularly so when the community comprises consumers with heterogeneous interests. This has made formal analysis of these markets improbable. In this paper, we remedy this by establishing robust connections between influence dynamics and optimization processes, in trial-offer markets where the consumer preferences are modelled by multinomial logit. Among other results, we show that the proportional-response-esque influence dynamic is equivalent to stochastic mirror descent on a convex objective function, thus leading to a stable and predictable outcome. When all consumers are homogeneous, the objective function has a natural interpretation as a weighted sum of efficiency and diversity of the culture market. In simulations driven by real-world preferences collected from a large-scale recommender system, we observe that ranking strategies aligned with the underlying heterogeneous preferences are more stable, and achieves higher efficiency and diversity. More broadly, we see this work as the first step in connecting computational methods for classical markets to the problem area of online attention and recommender systems. We hope this result paves the way to posing and answering a diverse set of research questions in this area.}
}

@inproceedings{Soen2022FairWF,
  title={Fair Wrapping for Black-box Predictions},
  author={Alexander Soen and Ibrahim M. Alabdulmohsin and Sanmi Koyejo and Y. Mansour and Nyalleng Moorosi and Richard Nock and Ke Sun and Lexing Xie},
  booktitle = {36th Conference on Neural Information Processing Systems (NeurIPS 2022)},
  year      = {2022},
  url_paper = {https://arxiv.org/pdf/2201.12947.pdf},
  url_abstract = {https://arxiv.org/abs/2201.12947},
  abstract  = {We introduce a new family of techniques to post-process ("wrap") a black-box classifier in order to reduce its bias. Our technique builds on the recent analysis of improper loss functions whose optimization can correct any twist in prediction, unfairness being treated as a twist. In the post-processing, we learn a wrapper function which we define as an α-tree, which modifies the prediction. We provide two generic boosting algorithms to learn α-trees. We show that our modification has appealing properties in terms of composition of α-trees, generalization, interpretability, and KL divergence between modified and original predictions. We exemplify the use of our technique in three fairness notions: conditional value-at-risk, equality of opportunity, and statistical parity; and provide experiments on several readily available datasets.}
}

@article{JMLR:v23:21-0917,
  author  = {Marian-Andrei Rizoiu and Alexander Soen and Shidi Li and Pio Calderon and Leanne J. Dong and Aditya Krishna Menon and Lexing Xie},
  title   = {Interval-censored Hawkes processes},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {338},
  pages   = {1--84},
  url_abstract    = {http://jmlr.org/papers/v23/21-0917.html},
  url_paper = {https://arxiv.org/pdf/2104.07932}, 
  abstract  = {Interval-censored data solely records the aggregated counts of events during specific time intervals -- such as the number of patients admitted to the hospital or the volume of vehicles passing traffic loop detectors -- and not the exact occurrence time of the events. It is currently not understood how to fit the Hawkes point processes to this kind of data. Its typical loss function (the point process log-likelihood) cannot be computed without exact event times. Furthermore, it does not have the independent increments property to use the Poisson likelihood. This work builds a novel point process, a set of tools, and approximations for fitting Hawkes processes within interval-censored data scenarios. First, we define the Mean Behavior Poisson process (MBPP), a novel Poisson process with a direct parameter correspondence to the popular self-exciting Hawkes process. We fit MBPP in the interval-censored setting using an interval-censored Poisson log-likelihood (IC-LL). We use the parameter equivalence to uncover the parameters of the associated Hawkes process. Second, we introduce two novel exogenous functions to distinguish the exogenous from the endogenous events. We propose the multi-impulse exogenous function -- for when the exogenous events are observed as event time -- and the latent homogeneous Poisson process exogenous function -- for when the exogenous events are presented as interval-censored volumes. Third, we provide several approximation methods to estimate the intensity and compensator function of MBPP when no analytical solution exists. Fourth and finally, we connect the interval-censored loss of MBPP to a broader class of Bregman divergence-based functions. Using the connection, we show that the popularity estimation algorithm Hawkes Intensity Process (HIP) is a particular case of the MBPP. We verify our models through empirical testing on synthetic data and real-world data. We find that our MBPP outperforms HIP on real-world datasets for the task of popularity prediction. This work makes it possible to efficiently fit the Hawkes process to interval-censored data.}
}


@inproceedings{Soen2022FairWF,
  title={Fair Wrapping for Black-box Predictions},
  author={Alexander Soen and Ibrahim M. Alabdulmohsin and Sanmi Koyejo and Y. Mansour and Nyalleng Moorosi and Richard Nock and Ke Sun and Lexing Xie},
  booktitle = {36th Conference on Neural Information Processing Systems (NeurIPS 2022)},
  year      = {2022},
  url_paper = {https://arxiv.org/pdf/2201.12947.pdf},
  abstract  = {We introduce a new family of techniques to post-process ("wrap") a black-box classifier in order to reduce its bias. Our technique builds on the recent analysis of improper loss functions whose optimization can correct any twist in prediction, unfairness being treated as a twist. In the post-processing, we learn a wrapper function which we define as an α-tree, which modifies the prediction. We provide two generic boosting algorithms to learn α-trees. We show that our modification has appealing properties in terms of composition of α-trees, generalization, interpretability, and KL divergence between modified and original predictions. We exemplify the use of our technique in three fairness notions: conditional value-at-risk, equality of opportunity, and statistical parity; and provide experiments on several readily available datasets.}
}


@inproceedings{10.1145/3340531.3411900, 
author = {Liu, Yuli}, 
title = {Recommending Inferior Results: A General and Feature-Free Model for Spam Detection},
year = {2020}, isbn = {9781450368599}, 
publisher = {Association for Computing Machinery}, 
address = {New York, NY, USA}, url = {https://doi.org/10.1145/3340531.3411900}, 
doi = {10.1145/3340531.3411900}, 
abstract = {Spam activities on multifarious online platforms, such as the opinion spam and fake following relationships have been extensively studied for years. Existing works separately employ hand-crafted features --- mainly extracted from user behavior, text information, and relational network, to detect the specific spamming phenomenon on a certain kind of online platform. Although these attempts have made some headway, rapidly emerging spamming categories and frequently changing cheating strategies lead detection models to be subject to circumscribed usability and fragile effectiveness.This paper is the first attempt to develop a general and feature-free fraud detection model, tackling the longstanding and thorny challenges in spam detection area. To achieve this, we first transform diverse relational networks that are contaminated by fraudsters into the unified matrix form. We then deal with the spam problem from a fresh perspective inspired by the pairwise learning thought in the area of recommender system. By comparing pairwise ranking relations of all the entities in the unified matrix, a new pairwise loss objective function is formulated to identify instances that occupy higher rankings as inferior (spamming) results. To further boost detection performance, we incorporate the pairwise ranking detection method and the widely used structure-based algorithm into an integrated framework. Experiments on real-word datasets of different Web applications show significant improvements of our proposed framework over competitive methods.}, 
booktitle = {Proceedings of the 29th ACM International Conference on Information & Knowledge Management}, 
pages = {955–974}, 
numpages = {20}, 
keywords = {label propagation, spam detection, pairwise ranking}, 
location = {Virtual Event, Ireland}, 
series = {CIKM '20} 
}

@inproceedings{10.1145/3477495.3531965,
author = {Liu, Yuli and Walder, Christian and Xie, Lexing},
title = {Determinantal Point Process Likelihoods for Sequential Recommendation},
year = {2022},
isbn = {9781450387323},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477495.3531965},
doi = {10.1145/3477495.3531965},
abstract = {Sequential recommendation is a popular task in academic research and close to real-world application scenarios, where the goal is to predict the next action(s) of the user based on his/her previous sequence of actions. In the training process of recommender systems, the loss function plays an essential role in guiding the optimization of recommendation models to generate accurate suggestions for users. However, most existing sequential recommendation tech- niques focus on designing algorithms or neural network architectures, and few efforts have been made to tailor loss functions that fit naturally into the practical application scenario of sequential recommender systems. Ranking-based losses, such as cross-entropy and Bayesian Personalized Ranking (BPR) are widely used in the sequential recommendation area. We argue that such objective functions suffer from two inherent drawbacks: i) the dependencies among elements of a sequence are overlooked in these loss formulations; ii) instead of balancing accuracy (quality) and diversity, only generating accurate results has been over emphasized. We therefore propose two new loss functions based on the Determinantal Point Process (DPP) likelihood, that can be adaptively applied to estimate the subsequent item or items. The DPP-distributed item set captures natural dependencies among temporal actions, and a quality vs. diversity decomposition of the DPP kernel pushes us to go beyond accuracy-oriented loss functions. Experimental results using the proposed loss functions on three real-world datasets show marked improvements over state-of-the-art sequential recommendation methods in both quality and diversity metrics.},
booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1653–1663},
numpages = {11},
keywords = {sequential recommendation, determinantal point process, loss function, diversity},
location = {Madrid, Spain},
series = {SIGIR '22}
}

@inproceedings{lucchesi2022smallset,
author = {Lucchesi, Lydia R. and Kuhnert, Petra M. and Davis, Jenny L. and Xie, Lexing},
title = {Smallset Timelines: A Visual Representation of Data Preprocessing Decisions},
year = {2022},
publisher = {Association for Computing Machinery},
booktitle = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
address = {New York, NY, USA},
doi = {https://doi.org/10.1145/3531146.3533175},
location = {Seoul, Korea},
series = {FAccT '22},
  url_abstract = {https://arxiv.org/abs/2206.04875},
  url_paper    = {https://arxiv.org/pdf/2206.04875.pdf},
  abstract = {Data preprocessing is a crucial stage in the data analysis pipeline, with both technical and social aspects to consider. Yet, the attention it receives is often lacking in research practice and dissemination. We present the Smallset Timeline, a visualisation to help reflect on and communicate data preprocessing decisions. A "Smallset" is a small selection of rows from the original dataset containing instances of dataset alterations. The Timeline is comprised of Smallset snapshots representing different points in the preprocessing stage and captions to describe the alterations visualised at each point. Edits, additions, and deletions to the dataset are highlighted with colour. We develop the R software package, smallsets, that can create Smallset Timelines from R and Python data preprocessing scripts. Constructing the figure asks practitioners to reflect on and revise decisions as necessary, while sharing it aims to make the process accessible to a diverse range of audiences. We present two case studies to illustrate use of the Smallset Timeline for visualising preprocessing decisions. Case studies include software defect data and income survey benchmark data, in which preprocessing affects levels of data loss and group fairness in prediction tasks, respectively. We envision Smallset Timelines as a go-to data provenance tool, enabling better documentation and communication of preprocessing tasks at large.}
}

@inproceedings{nguyen2022icwsm,
  author       = {Nguyen, Tuan Dung and Lyall, Georgiana and Tran, Alasdair and Shin, Minjeong and Carroll, Nicholas George and Klein, Colin and Xie, Lexing},
  title        = {Mapping Topics in 100,000 Real-life Moral Dilemmas},
  booktitle    = {International AAAI Conference on Web and Social Media (ICWSM '22)},
  year         = {2022},
  abstract     = {Moral dilemmas play an important role in theorizing both about ethical norms and moral psychology. Yet thought experiments borrowed from the philosophical literature often lack the nuances and complexity of real life. We leverage 100,000 threads -- the largest collection to date -- from  Reddit's r/AmItheAsshole to examine the features of everyday moral dilemmas.  Combining topic modeling with evaluation from both expert and crowd-sourced workers, we discover 47 fine-grained, meaningful topics and group them into five meta-categories. We show that most dilemmas combine at least two topics, such as family and money. We also observe that the pattern of topic co-occurrence carries interesting information about the structure of everyday moral concerns: for example, the generation of moral dilemmas from nominally neutral topics, and interaction effects in which final verdicts do not line up with the moral concerns in the original stories in any simple way. Our analysis demonstrates the utility of a fine-grained data-driven approach to online moral dilemmas, and provides a valuable resource for researchers aiming to explore the intersection of practical and theoretical ethics.},
  url          = {https://cecs.anu.edu.au/news/algorithm-charts-moral-culture-100k-dilemmas},
  url_abstract = {https://arxiv.org/abs/2203.16762},
  url_paper    = {http://cm.cecs.anu.edu.au/documents/nguyen_icwsm2022_mappingtopics.pdf}
}

@inproceedings{lee2022icwsm,
  author       = {Lee, JooYoung and Wu, Siqi and Ertugrul, Ali Mert and Lin, Yu-Ru and Xie, Lexing},
  title        = {Whose Advantage? Measuring Attention Dynamics across YouTube and Twitter on Controversial Topics},
  booktitle    = {International AAAI Conference on Web and Social Media (ICWSM '22)},
  year         = {2022},
  abstract     = {The ideological asymmetries have been recently observed in contested online spaces, where conservative voices seem to be relatively more pronounced even though liberals are known to have the population advantage on digital platforms. Most prior research, however, focused on either one single platform or one single political topic. Whether an ideological group garners more attention across platforms and/or topics, and how the attention dynamics evolve over time, have not been explored. In this work, we present a quantitative study that links collective attention across two social platforms -- YouTube and Twitter, centered on online activities surrounding popular videos of three controversial political topics including Abortion, Gun control, and Black Lives Matter over 16 months. We propose several sets of video-centric metrics to characterize how online attention is accumulated for different ideological groups. We find that neither side is on a winning streak: left-leaning videos are overall more viewed, more engaging, but less tweeted than right-leaning videos. The attention time series unfold quicker for left-leaning videos, but span a longer time for right-leaning videos. Network analysis on the early adopters and tweet cascades show that the information diffusion for left-leaning videos tends to involve centralized actors; while that for right-leaning videos starts earlier in the attention lifecycle. In sum, our findings go beyond the static picture of ideological asymmetries in digital spaces and provide a set of methods to quantify attention dynamics across different social platforms.},
  url          = {https://cecs.anu.edu.au/news/algorithm-charts-moral-culture-100k-dilemmas},
  url_abstract = {https://arxiv.org/abs/2204.00988},
  url_paper    = {http://cm.cecs.anu.edu.au/documents/lee_icwsm2022xplatform.pdf}
}

@inproceedings{shin2022tvcg,
  author    = {Shin, Minjeong and Kim, Joohee and Han, Yunha and Xie, Lexing and Whitelaw, Mitchell and Kwon, Bum Chul and Ko, Sungahn and Elmqvist, Niklas},
  journal   = {IEEE Transactions on Visualization and Computer Graphics},
  title     = {Roslingifier: Semi-Automated Storytelling for Animated Scatterplots},
  year      = {2022},
  abstract  = {We present Roslingifier, a data-driven storytelling method for animated scatterplots. Like its namesake, Hans Rosling (1948--2017), a professor of public health and a spellbinding public speaker, Roslingifier turns a sequence of entities changing over time---such as countries and continents with their demographic data---into an engaging narrative telling the story of the data. This data-driven storytelling method with an in-person presenter is a new genre of storytelling technique and has never been studied before. In this paper, we aim to define a design space for this new genre---data presentation---and provide a semi-automated authoring tool for helping presenters create quality presentations. From an in-depth analysis of video clips of presentations using interactive visualizations, we derive three specific techniques to achieve this: natural language narratives, visual effects that highlight events, and temporal branching that changes playback time of the animation. Our implementation of the Roslingifier method is capable of identifying and clustering significant movements, automatically generating visual highlighting and a narrative for playback, and enabling the user to customize. From two user studies, we show that Roslingifier allows users to effectively create engaging data stories and the system features help both presenters and viewers find diverse insights.},
  url_paper = {https://ieeexplore.ieee.org/abstract/document/9695173},
  doi       = {10.1109/TVCG.2022.3146329}
}

@article{zhang2020holo,
  title={Holo-UNet: hologram-to-hologram neural network restoration for high fidelity low light quantitative phase imaging of live cells},
  author={Zhang, Zhiduo and Zheng, Yujie and Xu, Tienan and Upadhya, Avinash and Lim, Yean Jin and Mathews, Alexander and Xie, Lexing and Lee, Woei Ming},
  journal={Biomedical optics express},
  volume={11},
  number={10},
  pages={5478--5487},
  year={2020},
  doi = {10.1364/BOE.395302},
  url_abstract = {https://opg.optica.org/boe/fulltext.cfm?uri=boe-11-10-5478&id=437960},
  url_paper    = {https://opg.optica.org/DirectPDFAccess/28B3E3DE-405F-4389-AE6FD4BE9A5B5AE2_437960/boe-11-10-5478.pdf}
}

@inproceedings{wu2021icwsm,
  author       = {Wu, Siqi and Resnick, Paul},
  title        = {Cross-Partisan Discussions on YouTube: Conservatives Talk to Liberals but Liberals Don’t Talk to Conservatives},
  booktitle    = {International AAAI Conference on Web and Social Media (ICWSM '21)},
  year         = {2021},
  abstract     = {We present the first large-scale measurement study of cross-partisan discussions between liberals and conservatives on YouTube, based on a dataset of 274,241 political videos from 973 channels of US partisan media and 134M comments from 9.3M users over eight months in 2020. Contrary to a simple narrative of echo chambers, we find a surprising amount of cross-talk: most users with at least 10 comments posted at least once on both left-leaning and right-leaning YouTube channels. Cross-talk, however, was not symmetric. Based on the user leaning predicted by a hierarchical attention model, we find that conservatives were much more likely to comment on left-leaning videos than liberals on right-leaning videos. Secondly, YouTube's comment sorting algorithm made cross-partisan comments modestly less visible; for example, comments from conservatives made up 26.3% of all comments on left-leaning videos but just over 20% of the comments were in the top 20 positions. Lastly, using Perspective API's toxicity score as a measure of quality, we find that conservatives were not significantly more toxic than liberals when users directly commented on the content of videos. However, when users replied to comments from other users, we find that cross-partisan replies were more toxic than co-partisan replies on both left-leaning and right-leaning videos, with cross-partisan replies being especially toxic on the replier's home turf.},
  url_abstract = {https://arxiv.org/abs/2104.05365},
  url_paper    = {http://cm.cecs.anu.edu.au/documents/wu_icwsm2021crosstalk.pdf},
  url_code     = {https://github.com/avalanchesiqi/youtube-crosstalk}
}

@phdthesis{Wu:2021:Thesis,
  author    = {Wu, Siqi},
  title     = {Measuring Collective Attention in Online Content: Sampling, Engagement, and Network Effects},
  year      = {2021},
  publisher = {The Australian National University},
  url       = {https://openresearch-repository.anu.edu.au/handle/1885/224512},
  url_paper = {http://cm.cecs.anu.edu.au/documents/wu_thesis.pdf},
  abstract  = {The production and consumption of online content have been increasing rapidly, whereas human attention is a scarce resource. Understanding how the content cap- tures collective attention has become a challenge of growing importance. In this thesis, we tackle this challenge from three fronts – quantifying sampling effects of social media data; measuring engagement behaviors towards online content; and estimating network effects induced by the recommender systems.
               Data sampling is a fundamental problem. To obtain a list of items, one common method is sampling based on the item prevalence in social media streams. However, social data is often noisy and incomplete, which may affect the subsequent observa- tions. For each item, user behaviors can be conceptualized as two steps – the first step is relevant to the content appeal, measured by the number of clicks; the second step is relevant to the content quality, measured by the post-clicking metrics, e.g., dwell time, likes, or comments. We categorize online attention (behaviors) into two classes: popularity (clicking) and engagement (watching, liking, or commenting). Moreover, modern platforms use recommender systems to present the users with a tailoring content display for maximizing satisfaction. The recommendation alters the appeal of an item by changing its ranking, and consequently impacts its popularity.
               Our research is enabled by the data available from the largest video hosting site YouTube. We use YouTube URLs shared on Twitter as a sampling protocol to obtain a collection of videos, and we track their prevalence from 2015 to 2019. This method creates a longitudinal dataset consisting of more than 5 billion tweets. Albeit the volume is substantial, we find Twitter still subsamples the data. Our dataset covers about 80% of all tweets with YouTube URLs. We present a comprehensive measure- ment study of the Twitter sampling effects across different timescales and different subjects. We find that the volume of missing tweets can be estimated by Twitter rate limit messages, true entity ranking can be inferred based on sampled observations, and sampling compromises the quality of network and diffusion models.
               Next, we present the first large-scale measurement study of how users collec- tively engage with YouTube videos. We study the time and percentage of each video being watched. We propose a duration-calibrated metric, called relative engagement, which is correlated with recognized notion of content quality, stable over time, and predictable even before a video’s upload.
               Lastly, we examine the network effects induced by the YouTube recommender system. We construct the recommendation network for 60,740 music videos from 4,435 professional artists. An edge indicates that the target video is recommended on the webpage of source video. We discover the popularity bias – videos are dis- proportionately recommended towards more popular videos. We use the bow-tie structure to characterize the network and find that the largest strongly connected component consists of 23.1% of videos while occupying 82.6% of attention. We also build models to estimate the latent influence between videos and artists. By taking into account the network structure, we can predict video popularity 9.7% better than other baselines.
               Altogether, we explore the collective consuming patterns of human attention to- wards online content. Methods and findings from this thesis can be used by content producers, hosting sites, and online users alike to improve content production, adver- tising strategies, and recommender systems. We expect our new metrics, methods, and observations can generalize to other multimedia platforms such as the music streaming service Spotify.}
}

@inproceedings{Kong2021,
  abstract      = {Modeling online discourse dynamics is a core activity in understanding the spread of information, both offline and online, and emergent online behavior. There is currently a disconnect between the practitioners of online social media analysis - usually social, political and communication scientists - and the accessibility to tools capable of handling large quantities of online data, and examining online users and their behavior. We present two tools,birdspotter and evently, for analyzing online users based on their involvement in retweet cascades. birdspotter provides a toolkit to measure social influence and botnets of Twitter users. While it leverages the multimodal information of tweets, such as text contents, evently augments the user measurement by modeling the temporal dynamics of information diffusions using self-exciting processes. Both tools are designed for users with a wide range of computer expertise and include tutorials and detailed documentation. We illustrate a case study of a topical dataset relating to COVID-19, using both tools for end-to-end analysis of online user behavior.},
  address       = {New York, NY, USA},
  archiveprefix = {arXiv},
  arxivid       = {2006.06167},
  author        = {Kong, Quyu and Ram, Rohit and Rizoiu, Marian-Andrei},
  booktitle     = {Proceedings of the 14th ACM International Conference on Web Search and Data Mining},
  doi           = {10.1145/3437963.3441708},
  eprint        = {2006.06167},
  isbn          = {9781450382977},
  month         = {mar},
  pages         = {1097--1100},
  publisher     = {ACM},
  title         = {{Evently: Modeling and Analyzing Reshare Cascades with Hawkes Processes}},
  url           = {https://dl.acm.org/doi/10.1145/3437963.3441708},
  year          = {2021},
  url_paper     = {https://arxiv.org/pdf/2006.06167.pdf},
  url_code      = {https://github.com/behavioral-ds/evently}
}

@inproceedings{tran2021radflow,
  author    = {Tran, Alasdair and Mathews, Alexander and Ong, Cheng Soon and Xie, Lexing},
  title     = {Radflow: A Recurrent, Aggregated, and Decomposable Model for Networks of Time Series},
  year      = {2021},
  publisher = {Association for Computing Machinery},
  doi       = {10.1145/3442381.3449945},
  booktitle = {Proceedings of The Web Conference 2021},
  url_paper = {https://arxiv.org/pdf/2102.07289.pdf},
  url_code  = {https://github.com/alasdairtran/radflow},
  abstract  = {We propose a new model for networks of time series that influence each other. Graph structures among time series are found in diverse domains, such as web traffic influenced by hyperlinks, product sales influenced by recommendation, or urban transport volume influenced by road networks and weather. There has been recent progress in graph modeling and in time series forecasting, respectively, but an expressive and scalable approach for a network of series does not yet exist. We introduce Radflow, a novel model that embodies three key ideas: a recurrent neural network to obtain node embeddings that depend on time, the aggregation of the flow of influence from neighboring nodes with multi-head attention, and the multi-layer decomposition of time series. Radflow naturally takes into account dynamic networks where nodes and edges change over time, and it can be used for prediction and data imputation tasks. On real-world datasets ranging from a few hundred to a few hundred thousand nodes, we observe that Radflow variants are the best performing model across a wide range of settings. The recurrent component in Radflow also outperforms N-BEATS, the state-of-the-art time series model. We show that Radflow can learn different trends and seasonal patterns, that it is robust to missing nodes and edges, and that correlated temporal patterns among network neighbors reflect influence strength. We curate WikiTraffic, the largest dynamic network of time series with 366K nodes and 22M time-dependent links spanning five years. This dataset provides an open benchmark for developing models in this area, with applications that include optimizing resources for the web. More broadly, Radflow has the potential to improve forecasts in correlated time series networks such as the stock market, and impute missing measurements in geographically dispersed networks of natural phenomena.}
}

@inproceedings{soen2021unipoint,
  author       = {Alexander Soen and Alexander Mathews and Daniel Grixti-Cheng and Lexing Xie},
  title        = {{UNIPoint}: Universally Approximating Point Processes Intensities},
  booktitle    = {AAAI Conference on Artificial Intelligence (AAAI)},
  year         = {2021},
  abstract     = {Point processes are a useful mathematical tool for describing events over time, and so there are many recent approaches for representing and learning them. One notable open question is how to precisely describe the flexibility of point process models and whether there exists a general model that can represent all point processes. Our work bridges this gap. Focusing on the widely used event intensity function representation of point processes, we provide a proof that a class of learnable functions can universally approximate any valid intensity function. The proof connects the well known Stone-Weierstrass Theorem for function approximation, the uniform density of non-negative continuous functions using a transfer functions, the formulation of the parameters of a piece-wise continuous functions as a dynamic system, and a recurrent neural network implementation for capturing the dynamics. Using these insights, we design and implement UNIPoint, a novel neural point process model, using recurrent neural networks to parameterise sums of basis function upon each event. Evaluations on synthetic and real world datasets show that this simpler representation performs better than Hawkes process variants and more complex neural network-based approaches. We expect this result will provide a practical basis for selecting and tuning models, as well as furthering theoretical work on representational complexity and learnability.},
  url_abstract = {https://arxiv.org/abs/2007.14082},
  url_paper    = {https://arxiv.org/pdf/2007.14082},
  url_code     = {https://github.com/alexandersoen/unipoint}
}

@inproceedings{shin2021attentionflow,
  author    = {Shin, Minjeong and Tran, Alasdair and Wu, Siqi and Mathews, Alexander and Wang, Rong and Lyall, Georgiana and Xie, Lexing},
  title     = {AttentionFlow: Visualising Influence in Networks of Time Series},
  year      = {2021},
  publisher = {Association for Computing Machinery},
  doi       = {10.1145/3437963.3441703},
  booktitle = {Proceedings of the 14th International Conference on Web Search and Data Mining, Demo},
  series    = {WSDM '21},
  url       = { https://attentionflow.cmlab.dev/},
  url_paper = {https://arxiv.org/pdf/2102.01974.pdf},
  url_code  = {https://github.com/alasdairtran/attentionflow},
  abstract  = {The collective attention on online items such as web pages, search terms, and videos reflects trends that are of social, cultural, and economic interest. Moreover, attention trends of different items exhibit mutual influence via mechanisms such as hyperlinks or recommendations. Many visualisation tools exist for time series, network evolution, or network influence; however, few systems connect all three. In this work, we present AttentionFlow, a new system to visualise networks of time series and the dynamic influence they have on one another. Centred around an ego node, our system simultaneously presents the time series on each node using two visual encodings: a tree ring for an overview and a line chart for details. AttentionFlow supports interactions such as overlaying time series of influence, and filtering neighbours by time or flux. We demonstrate AttentionFlow using two real-world datasets, Vevo and Wiki. We show that attention spikes in songs can be explained by external events such as major awards, or changes in the network such as the release of a new song. Separate case studies also demonstrate how an artist's influence changes over their career, and that correlated Wikipedia traffic is driven by cultural interests. More broadly, AttentionFlow can be generalised to visualise networks of time series on physical infrastructures such as road networks, or natural phenomena such as weather and geological measurements.}
}

@inproceedings{zhang2020neurips,
  author    = {Zhang, Rui and Walder, Christian J. and Bonilla, Edwin V. and Rizoiu, Marian-Andrei and Xie, Lexing},
  title     = {Quantile Propagation for Wasserstein-Approximate Gaussian Processes},
  booktitle = {34th Conference on Neural Information Processing Systems (NeurIPS 2020)},
  year      = {2020},
  url_paper = {https://arxiv.org/pdf/1912.10200.pdf},
  url_code  = {https://github.com/RuiZhang2016/Quantile-Propagation-for-Wasserstein-Approximate-Gaussian-Processes},
  abstract  = {Approximate inference techniques are the cornerstone of probabilistic methods based on Gaussian process priors. Despite this, most work approximately optimizes standard divergence measures such as the Kullback-Leibler (KL) divergence, which lack the basic desiderata for the task at hand, while chiefly offering merely technical convenience. We develop a new approximate inference method for Gaussian process models which overcomes the technical challenges arising from abandoning these convenient divergences. Our method---dubbed Quantile Propagation (QP)---is similar to expectation propagation (EP) but minimizes the L2 Wasserstein distance (WD) instead of the KL divergence. The WD exhibits all the required properties of a distance metric, while respecting the geometry of the underlying sample space. We show that QP matches quantile functions rather than moments as in EP and has the same mean update but a smaller variance update than EP, thereby alleviating EP's tendency to over-estimate posterior variances. Crucially, despite the significant complexity of dealing with the WD, QP has the same favorable locality property as EP, and thereby admits an efficient algorithm. Experiments on classification and Poisson regression show that QP outperforms both EP and variational Bayes.}
}

@inproceedings{kong2020cikm,
  author    = {Kong, Quyu and Rizoiu, Marian-Andrei and Xie, Lexing},
  title     = {Describing and Predicting Online Items with Reshare Cascades via Dual Mixture Self-exciting Processes},
  booktitle = {ACM International Conference on Information and Knowledge Management (CIKM'20)},
  pages     = {645--654},
  year      = {2020},
  url_paper = {https://arxiv.org/pdf/2001.11132.pdf},
  url_code  = {https://github.com/qykong/dual-mixture-hawkes-processes},
  abstract  = {It is well-known that online behavior is long-tailed, with most cascaded actions being short and a few being very long. A prominent drawback in generative models for online events is the inability to describe unpopular items well. This work addresses these shortcomings by proposing dual mixture self-exciting processes to jointly learn from groups of cascades. We first start from the observation that maximum likelihood estimates for content virality and influence decay are separable in a Hawkes process. Next, our proposed model, which leverages a Borel mixture model and a kernel mixture model, jointly models the unfolding of a heterogeneous set of cascades. When applied to cascades of the same online items, the model directly characterizes their spread dynamics and supplies interpretable quantities, such as content virality and content influence decay, as well as methods for predicting the final content popularities. On two retweet cascade datasets --- one relating to YouTube videos and the second relating to controversial news articles --- we show that our models capture the differences between online items at the granularity of items, publishers and categories. In particular, we are able to distinguish between far-right, conspiracy, controversial and reputable online news articles based on how they diffuse through social media, achieving an F1 score of 0.945. On holdout datasets, we show that the dual mixture model provides, for reshare diffusion cascades especially unpopular ones, better generalization performance and, for online items, accurate item popularity predictions.}
}

@inproceedings{cheng2020cikm,
  author       = {Cheng, Lu and Shu, Kai and Wu, Siqi and Silva, Yasin N. and Hall, Deborah L. and Liu, Huan},
  title        = {Unsupervised Cyberbullying Detection via Time-Informed Gaussian Mixture Model},
  booktitle    = {ACM International Conference on Information and Knowledge Management (CIKM'20)},
  pages        = {185–194},
  year         = {2020},
  url_abstract = {https://arxiv.org/abs/2008.02642},
  url_paper    = {http://cm.cecs.anu.edu.au/documents/cheng_cikm2020cyberbullying.pdf},
  url_code     = {https://github.com/GitHubLuCheng/UCD},
  abstract     = {Social media is a vital means for information-sharing due to its easy access, low cost, and fast dissemination characteristics. However, increases in social media usage have corresponded with a rise in the prevalence of cyberbullying. Most existing cyberbullying detection methods aresupervised and, thus, have two key drawbacks: (1) The data labeling process is often time-consuming and labor-intensive; (2) Current labeling guidelines may not be generalized to future instances because of different language usage and evolving social networks. To address these limitations, this work introduces a principled approach forunsupervised cyberbullying detection. The proposed model consists of two main components: (1) Arepresentation learning network that encodes the social media session by exploiting multi-modal features, e.g., text, network, and time. (2) Amulti-task learning network that simultaneously fits the comment inter-arrival times and estimates the bullying likelihood based on a Gaussian Mixture Model. The proposed model jointly optimizes the parameters of both components to overcome the shortcomings of decoupled training. Our core contribution is an unsupervised cyberbullying detection model that not only experimentally outperforms the state-of-the-art unsupervised models, but also achieves competitive performance compared to supervised models.}
}

@inproceedings{bista2020supmmd,
  title     = {SupMMD: A Sentence Importance Model for Extractive Summarization using Maximum Mean Discrepancy},
  author    = {Bista, Umanga and Mathews, Alexander Patrick and Menon, Aditya Krishna and Xie, Lexing},
  booktitle = {Empirical Methods in Natural Language Processing Findings (EMNLP Findings)},
  year      = {2020},
  url_paper = {https://arxiv.org/pdf/2010.02568.pdf},
  url_code  = {https://github.com/computationalmedia/supmmd},
  abstract  = { Most work on multi-document summarization has focused on generic summarization of information present in each individual document set. However, the under-explored setting of update summarization, where the goal is to identify the new information present in each set, is of equal practical interest (e.g., presenting readers with updates on an evolving news topic). In this work, we present SupMMD, a novel technique for generic and update summarization based on the maximum mean discrepancy from kernel two-sample testing. SupMMD combines both supervised learning for salience and unsupervised learning for coverage and diversity. Further, we adapt multiple kernel learning to make use of similarity across multiple information sources (e.g., text features and knowledge based concepts). We show the efficacy of SupMMD in both generic and update summarization tasks by meeting or exceeding the current state-of-the-art on the DUC-2004 and TAC-2009 datasets.}
}

@article{toyer2020asnets,
  author    = {Sam Toyer and Sylvie Thi{\'{e}}baux and Felipe W. Trevizan and Lexing Xie},
  title     = {ASNets: Deep Learning for Generalised Planning},
  journal   = {J. Artif. Intell. Res.},
  volume    = {68},
  pages     = {1--68},
  year      = {2020},
  url       = {https://doi.org/10.1613/jair.1.11633},
  doi       = {10.1613/jair.1.11633},
  url_paper = {http://cm.cecs.anu.edu.au/documents/toyer2020asnets.pdf},
  abstract  = {In this paper, we discuss the learning of generalised policies for probabilistic and clas- sical planning problems using Action Schema Networks (ASNets). The ASNet is a neural network architecture that exploits the relational structure of (P)PDDL planning problems to learn a common set of weights that can be applied to any problem in a domain. By mimicking the actions chosen by a traditional, non-learning planner on a handful of small problems in a domain, ASNets are able to learn a generalised reactive policy that can quickly solve much larger instances from the domain. This work extends the ASNet archi- tecture to make it more expressive, while still remaining invariant to a range of symmetries that exist in PPDDL problems. We also present a thorough experimental evaluation of ASNets, including a comparison with heuristic search planners on seven probabilistic and deterministic domains, an extended evaluation on over 18,000 Blocksworld instances, and an ablation study. Finally, we show that sparsity-inducing regularisation can produce AS- Nets that are compact enough for humans to understand, yielding insights into how the structure of ASNets allows them to generalise across a domain.}
}

@inproceedings{Tran2020Tell,
  author    = {Tran, Alasdair and Mathews, Alexander and Xie, Lexing},
  title     = {{Transform and Tell: Entity-Aware News Image Captioning}},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2020},
  abstract  = {We propose an end-to-end model which generates captions for images embedded in news articles. News images present two key challenges: they rely on real-world knowledge, especially about named entities; and they typically have linguistically rich captions that include uncommon words. We address the first challenge by associating words in the caption with faces and objects in the image, via a multi-modal, multi-head attention mechanism. We tackle the second challenge with a state-of-the-art transformer language model that uses byte-pair-encoding to generate captions as a sequence of word parts. On the GoodNews dataset, our model outperforms the previous state of the art by a factor of four in CIDEr score (13 to 54). This performance gain comes from a unique combination of language models, word representation, image embeddings, face embeddings, object embeddings, and improvements in neural network design. We also introduce the NYTimes800k dataset which is 70% larger than GoodNews, has higher article quality, and includes the locations of images within articles as an additional contextual cue.},
  url       = {https://transformandtell.cmlab.dev/},
  url_paper = {http://cm.cecs.anu.edu.au/documents/tran-transform-and-tell-cpvr-2020.pdf},
  url_code  = {https://github.com/alasdairtran/transform-and-tell}
}

@inproceedings{wu2020variation,
  address      = {Atlanta, GA, USA},
  author       = {Wu, Siqi and Rizoiu, Marian-Andrei and Xie, Lexing},
  booktitle    = {International AAAI Conference on Web and Social Media (ICWSM '20)},
  title        = {Variation across Scales: Measurement Fidelity under Twitter Data Sampling},
  year         = {2020},
  abstract     = {A comprehensive understanding of data quality is the cornerstone of measurement studies in social media research. This paper presents in-depth measurements on the effects of Twitter data sampling across different timescales and different subjects (entities, networks, and cascades). By constructing complete tweet streams, we show that Twitter rate limit message is an accurate indicator for the volume of missing tweets. Sampling also differs significantly across timescales. While the hourly sampling rate is influenced by the diurnal rhythm in different time zones, the millisecond level sampling is heavily affected by the implementation choices. For Twitter entities such as users, we find the Bernoulli process with a uniform rate approximates the empirical distributions well. It also allows us to estimate the true ranking with the observed sample data. For networks on Twitter, their structures are altered significantly and some components are more likely to be preserved. For retweet cascades, we observe changes in distributions of tweet inter-arrival time and user influence, which will affect models that rely on these features. This work calls attention to noises and potential biases in social data, and provides a few tools to measure Twitter sampling effects.},
  url_abstract = {https://arxiv.org/abs/2003.09557},
  url_paper    = {http://cm.cecs.anu.edu.au/documents/wu_icwsm2020_sampling.pdf},
  url_data     = {https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/GW9GDM},
  url_code     = {https://github.com/avalanchesiqi/twitter-sampling}
}

@inproceedings{zhang-aaai2020,
  title     = {Variational Inference for Sparse Gaussian Process Modulated Hawkes Process},
  author    = {Zhang, Rui and Walder, Christian and Rizoiu, Marian-Andrei},
  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
  year      = {2020},
  abstract  = {The Hawkes process (HP) has been widely applied to modeling self-exciting events including neuron spikes, earthquakes and tweets. To avoid designing parametric triggering kernel and to be able to quantify the prediction confidence, the non-parametric Bayesian HP has been proposed. However, the inference of such models suffers from unscalability or slow convergence. In this paper, we aim to solve both problems. Specifically, first, we propose a new non-parametric Bayesian HP in which the triggering kernel is modeled as a squared sparse Gaussian process. Then, we propose a novel variational inference schema for model optimization. We employ the branching structure of the HP so that maximization of evidence lower bound (ELBO) is tractable by the expectation-maximization algorithm. We propose a tighter ELBO which improves the fitting performance. Further, we accelerate the novel variational inference schema to linear time complexity by leveraging the stationarity of the triggering kernel. Different from prior acceleration methods, ours enjoys higher efficiency. Finally, we exploit synthetic data and two large social media datasets to evaluate our method. We show that our approach outperforms state-of-the-art non-parametric frequentist and Bayesian methods. We validate the efficiency of our accelerated variational inference schema and practical utility of our tighter ELBO for model selection. We observe that the tighter ELBO exceeds the common one in model selection.},
  url_paper = {https://arxiv.org/abs/1905.10496},
  url_code  = {https://github.com/RuiZhang2016/Variational-Inference-for-SGP-Modulated-Hawkes-Process}
}

@inproceedings{kong2020modeling,
  title     = {Modeling Information Cascades with Self-exciting Processes via Generalized Epidemic Models},
  author    = {Kong, Quyu and Rizoiu, Marian-Andrei and Xie, Lexing},
  booktitle = {ACM International Conference on Web Search and Data Mining (WSDM)},
  year      = {2020},
  abstract  = {Epidemic models and self-exciting processes are two types of models used to describe diffusion phenomena online and offline. These models were originally developed in different scientific communities, and their commonalities are under-explored. This work establishes, for the first time, a general connection between the two model classes via three new mathematical components. The first is a generalized version of stochastic Susceptible-Infected-Recovered (SIR) model with arbitrary recovery time distributions; the second is the relationship between the (latent and arbitrary) recovery time distribution, recovery hazard function, and the infection kernel of self-exciting processes; the third includes methods for simulating, fitting, evaluating and predicting the generalized process. On three large Twitter diffusion datasets, we conduct goodness-of-fit tests and holdout log-likelihood evaluation of self-exciting processes with three infection kernels --- exponential, power-law and Tsallis Q-exponential. We show that the modeling performance of the infection kernels varies with respect to the temporal structures of diffusions, and also with respect to user behavior, such as the likelihood of being bots. We further improve the prediction of popularity by combining two models that are identified as complementary by the goodness-of-fit tests.},
  url_paper = {https://arxiv.org/abs/1910.05451},
  url_code  = {https://github.com/qykong/generalized-sir-and-hawkes}
}

@phdthesis{Mishra:2019:Thesis,
  author    = {Mishra, Swapnil},
  title     = {Linking Models for Collective Attention in Social Media},
  year      = {2019},
  publisher = {The Australian National University},
  url       = {https://openresearch-repository.anu.edu.au/handle/1885/182586},
  url_paper = {https://openresearch-repository.anu.edu.au/bitstream/1885/182586/1/Mishra%20thesis%202019.pdf},
  abstract  = {Social networks are ubiquitous in the modern world for propagating and acquiring information. Thus, understanding and predicting the popularity of online information is an important problem in social media analysis. Considerable progress has been made recently in data-driven predictions, and in linking popularity to various external factors. Most of the work on popularity prediction and understanding is either based on learning a variety of features from full network data or using generative processes to model the event time data. However, there exists no prior work that connects or compares models across different paradigms. Accordingly, this thesis focuses on developing and connecting models to predict and understand popularity across different paradigms and settings. To this aim, we first bridge gaps between feature-driven and generative models with the help of a hybrid model and a new performance benchmark. We model each social diffusion with a marked Hawkes self-exciting point process, and we estimate from data the content virality, memory decay, and user influence. Next, we learn a predictive layer for popularity prediction using a collection of cascade histories. We show the Hawkes process with a predictive overlay outperforms recent feature-driven and generative approaches on both existing tweets data and our new dataset. We also show that a feature-driven method based on a basic set of user features and event time summary statistics performs competitively in both classification and regression tasks and that adding point process information to the feature set further improves predictions. A common benchmark dataset for popularity prediction helps us to utilize both feature-driven, and generative paradigms to better predict and understand online popularity. As the first proposed work that links models across feature-driven and generative models, our work has influenced subsequent works on online popularity since its publication in 2016. Secondly, we identify that the existing methods for popularity modeling and prediction typically focus on a single source of external influence. However, for many types of online content such as YouTube videos or news articles, attention is driven by multiple heterogeneous sources simultaneously - e.g., microblogs and traditional media coverage. Correspondingly, we propose RNN-MAS, a recurrent neural network for modeling asynchronous streams. It is a sequence generator that connects multiple streams of different granularity via joint inference. We show that RNN-MAS not only outperforms the current state-of-the-art YouTube popularity prediction system, but it also captures complex dynamics, such as the seasonal trends of unseen influence. Further, to increase the explainability and interpretability of our model, we propose two new metrics: the \emph{\promotionresponse} quantifies the gain in popularity from one unit of promotion for a YouTube video; the \emph{loudness level} captures the effects of a particular user tweeting about the video. We use the loudness level to compare the effects of a video being promoted by a single highly-followed user (in the top $1\%$ most followed users) against the same video being promoted by a group of mid-followed users. We show that results depend on the type of content being promoted: superusers are more successful in promoting Howto and Gaming videos, whereas the cohort of regular users is more influential for Activism videos. Additionally, we apply the RNN-MAS model to the problem of predicting the popularity of an item before being published. We train a single model for a group of videos to learn possible evolution dynamics of a given video from the historical data of the videos in the same group. A novel simulation strategy based on the proposed metrics enables us to simulate a representative promotion for the video, and predict the achieved popularity before it is published. Experiments on our large scale YouTube dataset show that our proposed method outperforms non-trivial baselines. By and large, this thesis proposes models for popularity modeling and prediction that are the first of their kind, and it links models across various paradigms and data availability. This work provides accurate and explainable popularity predictions, as well as computational tools for content producers and marketers to allocate resources for promotion campaigns. In addition to these contributions, this work may contribute to a more comprehensive understanding of popularity prediction and understanding models across different classes or types.}
}

@phdthesis{Chen:2019:Thesis,
  title     = {Recommending Structured Objects: Paths and Sets},
  author    = {Chen, Dawei},
  year      = {2019},
  publisher = {The Australian National University},
  url       = {https://openresearch-repository.anu.edu.au/handle/1885/165008},
  url_paper = {https://openresearch-repository.anu.edu.au/bitstream/1885/165008/1/thesis_chen_20190812_signed.pdf},
  abstract  = {Recommender systems have been widely adopted in industry to help people find the most appropriate items
               to purchase or consume from the increasingly large collection of available resources (e.g., books, songs and movies).
               Conventional recommendation techniques follow the approach of ``ranking all possible options and pick the top'',
               which can work effectively for single item recommendation but fall short when the item in question has internal structures.
               For example, a travel trajectory with a sequence of points-of-interest or a music playlist with a set of songs.
               Such structured objects pose critical challenges to recommender systems due to the intractability of ranking all possible
               candidates. This thesis study the problem of recommending structured objects, in particular, the recommendation of path
               (a sequence of unique elements) and set (a collection of distinct elements). We study the problem of recommending travel
               trajectories in a city, which is a typical instance of path recommendation. We propose methods that combine learning to
               rank and route planning techniques for efficient trajectory recommendation. Another contribution of this thesis is to
               develop the structured recommendation approach for path recommendation by substantially modifying the loss function,
               the learning and inference procedures of structured support vector machines. A novel application of path decoding techniques
               helps us achieve efficient learning and recommendation. Additionally, we investigate the problem of recommending a set of songs
               to form a playlist as an example of the set recommendation problem. We propose to jointly learn user representations by employing
               the multi-task learning paradigm, and a key result of equivalence between bipartite ranking and binary classification enables
               efficient learning of our set recommendation method. Extensive evaluations on real world datasets demonstrate the effectiveness
               of our proposed approaches for path and set recommendation.}
}

@inproceedings{wu2019estimating,
  address      = {Austin, TX, USA},
  author       = {Wu, Siqi and Rizoiu, Marian-Andrei and Xie, Lexing},
  booktitle    = {ACM Conference on Computer-Supported Cooperative Work and Social Computing (CSCW '19)},
  title        = {Estimating Attention Flow in Online Video Networks},
  year         = {2019},
  abstract     = {Online videos have shown tremendous increase in Internet traffic. Most video hosting sites implement recommender systems, which connect the videos into a directed network and conceptually act as a source of pathways for users to navigate. At present, little is known about how human attention is allocated over such large-scale networks, and about the impacts of the recommender systems. In this paper, we first construct the Vevo network -- a YouTube video network with 60,740 music videos interconnected by the recommendation links, and we collect their associated viewing dynamics. This results in a total of 310 million views every day over a period of 9 weeks. Next, we present large-scale measurements that connect the structure of the recommendation network and the video attention dynamics. We use the bow-tie structure to characterize the Vevo network and we find that its core component (23.1% of the videos), which occupies most of the attention (82.6% of the views), is made out of videos that are mainly recommended among themselves. This is indicative of the links between video recommendation and the inequality of attention allocation. Finally, we address the task of estimating the attention flow in the video recommendation network. We propose a model that accounts for the network effects for predicting video popularity, and we show it consistently outperforms the baselines. This model also identifies a group of artists gaining attention because of the recommendation network. Altogether, our observations and our models provide a new set of tools to better understand the impacts of recommender systems on collective social attention.},
  url_abstract = {https://arxiv.org/abs/1908.07123},
  url_paper    = {http://cm.cecs.anu.edu.au/documents/wu_cscw2019_network.pdf},
  url_data     = {https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/TORICY},
  url_code     = {https://github.com/avalanchesiqi/networked-popularity},
  url_slides   = {http://users.cecs.anu.edu.au/~siqi.wu/files/cscw2019slides.pdf},
  url_blog     = {https://medium.com/acm-cscw/how-does-the-network-of-youtube-music-videos-drive-attention-42130144b59b}
}

@inproceedings{shin2019influence,
  title      = {Influence Flowers of Academic Entities},
  author     = {Shin, Minjeong and Soen, Alexander and Readshaw, Benjamin T and Blackburn, Stephen M and Whitelaw, Mitchell and Xie, Lexing},
  booktitle  = {IEEE Conference on Visual Analytics Science and Technology (VAST)},
  year       = {2019},
  url_paper  = {https://arxiv.org/abs/1907.12748},
  url_code   = {http://influencemap.ml/vast19},
  url_slides = {http://cm.cecs.anu.edu.au/documents/shin_vast19_slides.pdf},
  abstract   = {We present the Influence Flower, a new visual metaphor for the influence profile of academic entities, including people, projects, institutions, conferences, and journals. While many tools quantify influence, we aim to expose the flow of influence between entities. The Influence Flower is an ego-centric graph, with a query entity placed in the centre. The petals are styled to reflect the strength of influence to and from other entities of the same or different type. For example, one can break down the incoming and outgoing influences of a research lab by research topics. The Influence Flower uses a recent snapshot of Microsoft Academic Graph, consisting of 200+ million authors, their publications, and 1+ billion citations. An interactive web app, Influence Map, is constructed around this central metaphor for searching and curating visualisations. We also propose a visual comparison method that highlights change in influence patterns over time. We demonstrate through several case studies that the Influence Flower supports data-driven inquiries about the following: researchers’ careers over time; paper(s) and projects, including those with delayed recognition; the interdiciplinary profile of a research institution; and the shifting topical trends in conferences. We also use this tool on influence data beyond academic citations, by contrasting the academic and twitter activities of a researcher.}
}

@inproceedings{zhang2019efficient,
  author    = {Rui Zhang and Christian Walder and Marian-Andrei Rizoiu and Lexing Xie},
  title     = {Efﬁcient Non-parametric Bayesian Hawkes Processes},
  booktitle = {The 28th International Joint Conference on Artificial Intelligence (IJCAI-19)},
  year      = {2019},
  address   = {Macau, China},
  abstract  = {In this paper, we develop an efﬁcient non-parametric Bayesian estimation of the kernel function of Hawkes processes. The non-parametric Bayesian approach is important because it provides ﬂexible Hawkes kernels and quantiﬁes their uncertainty. Our method is based on the cluster representation of Hawkes processes. Utilizing the stationarity of the Hawkes process, we efﬁciently sample random branching structures and thus, we split the Hawkes process into clusters of Poisson processes. We derive two algorithms — a block Gibbs sampler and a maximum a posteriori estimator based on expectation maximization — and we show that our methods have a linear time complexity, both theoretically and empirically. On synthetic data, we show our methods to be able to infer ﬂexible Hawkes triggering kernels. On two large scale Twitter diffusion datasets, we show that our methods outperform the current state-of-the-art in goodness-of-ﬁt and that the time complexity is linear in the size of the dataset. We also observe that on diffusions related to online videos, the learned kernels reﬂect the perceived longevity for different content types such as music or pets videos.},
  url_paper = {https://arxiv.org/abs/1810.03730},
  url_code  = {https://github.com/RuiZhang2016/Efficient-Nonparametric-Bayesian-Hawkes-Processes}
}

@article{Kim2019,
  author   = {Kim, Dongwoo and Graham, Timothy and Wan, Zimin and Rizoiu, Marian-Andrei},
  title    = {Analysing user identity via time-sensitive semantic edit distance (t-SED): a case study of Russian trolls on Twitter},
  journal  = {Journal of Computational Social Science},
  year     = {2019},
  month    = {Jul},
  day      = {01},
  volume   = {2},
  number   = {2},
  pages    = {331--351},
  abstract = {In the digital era, individuals are increasingly profiled and grouped based on the traces that they leave behind in online social networks such as Twitter and Facebook. In this paper, we develop and evaluate a novel text analysis approach for studying user identity and social roles by redefining identity as a sequence of timestamped items (e.g., tweet texts). We operationalise this idea by developing a novel text distance metric, the time-sensitive semantic edit distance (t-SED), which accounts for the temporal context across multiple traces. To evaluate this method, we undertake a case study of Russian online-troll activity within US political discourse. The novel metric allows us to classify the social roles of trolls based on their traces, in this case tweets, into one of the predefined categories left-leaning, right-leaning, and news feed. We show the effectiveness of the t-SED metric to measure the similarities between tweets while accounting for the temporal context, and we use novel data visualisation techniques and qualitative analysis to uncover new empirical insights into Russian troll activity that have not been identified in the previous work. In addition, we highlight a connection with the field of actor--network theory and the related hypotheses of Gabriel Tarde, and we discuss how social sequence analysis using t-SED may provide new avenues for tackling a longstanding problem in social theory: how to analyse society without separating reality into micro vs. macro-levels.},
  issn     = {2432-2725},
  doi      = {10.1007/s42001-019-00051-x},
  url      = {https://doi.org/10.1007/s42001-019-00051-x}
}

@article{Berger:2019:GRC:3342113.3332803,
  author     = {Berger, Emery and Blackburn, Stephen M. and Brodley, Carla and Jagadish, H. V. and McKinley, Kathryn S. and Nascimento, Mario A. and Shin, Minjeong and Wang, Kuansan and Xie, Lexing},
  title      = {GOTO Rankings Considered Helpful},
  journal    = {Commun. ACM},
  issue_date = {July 2019},
  volume     = {62},
  number     = {7},
  month      = jun,
  year       = {2019},
  issn       = {0001-0782},
  pages      = {29--30},
  numpages   = {2},
  url        = {http://doi.acm.org/10.1145/3332803},
  doi        = {10.1145/3332803},
  acmid      = {3332803},
  publisher  = {ACM},
  address    = {New York, NY, USA},
  url_paper  = {https://cacm.acm.org/magazines/2019/7/237709-goto-rankings-considered-helpful/fulltext}
}

@inproceedings{shin2019kgdiff,
  address   = {Melbourne, VIC, Australia},
  author    = {Shin, Minjeong and Kim, Dongwoo and Lee, Jae Hee and Bista, Umanga and Xie, Lexing},
  booktitle = {ACM International Conference on Web Search and Data Mining (WSDM '19), Demo},
  title     = {{Visualizing Graph Differences from Social Media Streams}},
  year      = {2019},
  abstract  = {We propose KGdiff, a new interactive visualization tool for social media content focusing on entities and relationships. The core component is a layout algorithm that highlights the differences between two graphs. We apply this algorithm on knowledge graphs consisting of named entities and their relations extracted from text streams over different time periods. The visualization system provides additional information such as the volume and frequency ranking of entities and allows users to select which parts of the graph to visualize interactively. On Twitter and news article collections, KGdiff allows users to compare different data subsets. Results of such comparisons often reveal topical or geographical changes in a discussion. More broadly, graph differences are useful for a wide range of relational data comparison tasks, such as comparing social interaction graphs, identifying changes in user behavior, or discovering differences in graphs from distinct sources, geography, or political stance.},
  url_paper = {http://cm.cecs.anu.edu.au/documents/shin_wsdm2019_demo.pdf}
}

@inproceedings{bista2019compdc,
  address   = {Melbourne, VIC, Australia},
  author    = {Bista, Umanga},
  booktitle = {ACM International Conference on Web Search and Data Mining (WSDM '19), Doctoral Consortium},
  title     = {Comparative summarisation of rich media collections},
  year      = {2019},
  abstract  = {The goal of this thesis is to develop techniques for comparative summarisation of multimodal document collections. Comparative summarisation is extractive summarisation in comparative settings, where documents form two or more groups, e.g. articles on the same topic but from different sources. Comparative summarisa- tion involves, not only, selecting representative and diverse sam- ples within groups, but also samples that highlight commonalities and differences between the groups. We posit that comparative summarisation is a fruitful problem for diverse use cases, such as comparing content over time, authors, or distinct view points. We formulate the problem of comparative summarisation by reducing it to binary classification problem and define objectives to incorpo- rate representativeness, diversity and comparativeness. We design new automatic and crowd-sourced evaluation protocols for sum- marisation evaluation that scales much better than the evaluations requiring manually created ground truth summaries. We show the efficacy of the approach in a newly curated datasets of controver- sial news topics. We plan to develop new collection comparison methods for multimodal document collections.},
  url_paper = {http://www.bistaumanga.com.np/files/compsumm_wsdm_dc.pdf}
}

@inproceedings{mishra2019bridging,
  author    = {Mishra, Swapnil},
  title     = {Bridging Models for Popularity Prediction on Social Media},
  booktitle = {Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining},
  series    = {WSDM '19},
  year      = {2019},
  isbn      = {978-1-4503-5940-5},
  location  = {Melbourne VIC, Australia},
  abstract  = {Understanding and predicting the popularity of online items is an important open problem in social media analysis. Most of the recent work on popularity prediction is either based on learning a variety of features from full network data or using generative processes to model the event time data. We identify two gaps in the current state of the art prediction models. The first is the unexplored connection and comparison between the two aforementioned approaches. In our work, we bridge gap between feature-driven and generative models by modelling social cascade with a marked Hawkes self-exciting point process. We then learn a predictive layer on top for popularity prediction using a collection of cascade history. Secondly, the existing methods typically focus on a single source of external influence, whereas for many types of online content such as YouTube videos or news articles, attention is driven by multiple heterogeneous sources simultaneously - e.g. microblogs or traditional media coverage. We propose a recurrent neural network based model for asynchronous streams that connects multiple streams of different granularity via joint inference. We further design two new measures, one to explain the viral potential of videos, the other to uncover latent influences including seasonal trends. This work provides accurate and explainable popularity predictions, as well as computational tools for content producers and marketers to allocate resources for promotion campaigns.},
  pages     = {810--811},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/3289600.3291598},
  doi       = {10.1145/3289600.3291598},
  acmid     = {3291598},
  publisher = {ACM},
  address   = {Melbourne, VIC, Australia},
  keywords  = {hawkes processes, information diffusion, recurrent neural networks},
  url_paper = {https://dl.acm.org/ft_gateway.cfm?id=3291598&ftid=2038013&dwn=1&CFID=108404766&CFTOKEN=bb5b0fef428247e0-52916DAC-902E-2E17-B7813EFE4C960CE8}
}

@inproceedings{wu2019attention,
  address   = {Melbourne, VIC, Australia},
  author    = {Wu, Siqi},
  booktitle = {ACM International Conference on Web Search and Data Mining (WSDM '19), Doctoral Consortium},
  title     = {How is Attention Allocated? Data-driven Studies of Popularity and Engagement in Online Videos},
  year      = {2019},
  abstract  = {The share of videos on Internet traffic has been growing, e.g., people are now spending a billion hours watching YouTube videos every day. Therefore, understanding how videos capture attention on a global scale is also of growing importance for both research and practice. In online platforms, people can interact with videos in different ways -- there are behaviors of active participation (watching, commenting, and sharing) and that of passive consumption (viewing). In this paper, we take a data-driven approach to studying how human attention is allocated in online videos with respect to both active and passive behaviors. We first investigate the active interaction behaviors by proposing a novel metric to represent the aggregate user engagement on YouTube videos. We show this metric is correlated with video quality, stable over lifetime, and predictable before video's upload. Next, we extend the line of work on modelling video view counts by disentangling the effects of two dominant traffic sources -- related videos and YouTube search. Findings from this work can help content producers to create engaging videos and hosting platforms to optimize advertising strategies, recommender systems, and many more applications.},
  url_paper = {http://cm.cecs.anu.edu.au/documents/wu_wsdm2019_dc.pdf}
}

@inproceedings{kong2019linking,
  address   = {Melbourne, VIC, Australia},
  author    = {Kong, Quyu},
  booktitle = {ACM International Conference on Web Search and Data Mining (WSDM '19), Doctoral Consortium},
  title     = {{Linking Epidemic Models and Hawkes Point Processes for Modeling Information Diffusion}},
  year      = {2019},
  abstract  = {Epidemic models and Hawkes point process models are two common model classes for information diffusion. Recent work has revealed the equivalence between the two for information diffusion modeling. This allows tools created for one class of models to be applied to another. However, epidemic models and Hawkes point processes can be connected in more ways. This thesis aims to develop a rich set of mathematical equivalences and extensions, and use them to ask and answer questions in social media and beyond. Specifically, we show our plan of generalizing the equivalence of the two model classes by extending it to Hawkes point process models with arbitrary memory kernels. We then outline a rich set of quantities describing diffusion, including diffusion size and extinction probability, introduced in the fields where the models are originally designed. Lastly, we discuss some novel applications of these quantities in a range of problems such as popularity prediction and popularity intervention.},
  url_paper = {http://cm.cecs.anu.edu.au/documents/kong_wsdm2019_dc.pdf}
}

@inproceedings{bista2019comp,
  author       = {Umanga Bista and Alexander Patrick Mathews and Minjeong Shin and Aditya Krishna Menon and Lexing Xie},
  title        = {Comparative Document Summarisation via Classification},
  booktitle    = {AAAI Conference on Artificial Intelligence (AAAI)},
  year         = {2019},
  address      = {Honolulu, USA},
  abstract     = {This paper considers extractive summarisation in a comparative setting: given two or more document groups (e.g., separated by publication time), the goal is to select a small number of documents that are representative of each group, and also maximally distinguishable from other groups. We formulate a set of new objective functions for this problem that connect recent literature on document summarisation, interpretable machine learning, and data subset selection. In particular, by casting the problem as a binary classification amongst different groups, we derive objectives based on the notion of maximum mean discrepancy, as well as a simple yet effective gradient-based optimisation strategy. Our new formulation allows scalable evaluations of comparative summarisation as a classification task, both automatically and via crowd-sourcing. To this end, we evaluate comparative summarisation methods on a newly curated collection of controversial news topics over 13 months. We observe that gradient-based optimisation outperforms discrete and baseline approaches in 15 out of 24 different automatic evaluation settings. In crowd-sourced evaluations, summaries from gradient optimisation elicit 7% more accurate classification from human workers than discrete optimisation. Our result contrasts with recent literature on submodular data subset selection that favours discrete optimisation. We posit that our formulation of comparative summarisation will prove useful in a diverse range of use cases such as comparing content sources, authors, related topics, or distinct view points.},
  url_abstract = {http://arxiv.org/abs/1812.02171},
  url_paper    = {http://arxiv.org/abs/1812.02171},
  url_code     = {https://github.com/computationalmedia/compsumm}
}

@phdthesis{mathews2018automatic,
  title     = {Automatic Image Captioning with Style},
  author    = {Mathews, Alexander Patrick},
  year      = {2018},
  publisher = {The Australian National University},
  url       = {https://openresearch-repository.anu.edu.au/handle/1885/151929},
  url_paper = {https://openresearch-repository.anu.edu.au/bitstream/1885/151929/1/thesis_apm_01_11_18.pdf},
  abstract  = {This thesis connects two core topics in machine learning, vision and language. The problem of choice is image caption generation: automatically constructing natural language descriptions of image content. Previous research into image caption generation has focused on generating purely descriptive captions; I focus on generating visually relevant captions with a distinct linguistic style. Captions with style have the potential to ease communication and add a new layer of personalisation. First, I consider naming variations in image captions, and propose a method for predicting context-dependent names that takes into account visual and linguistic information. This method makes use of a large-scale image caption dataset, which I also use to explore naming conventions and report naming conventions for hundreds of animal classes. Next I propose the SentiCap model, which relies on recent advances in artificial neural networks to generate visually relevant image captions with positive or negative sentiment. To balance descriptiveness and sentiment, the SentiCap model dynamically switches between two recurrent neural networks, one tuned for descriptive words and one for sentiment words. As the first published model for generating captions with sentiment, SentiCap has influenced a number of subsequent works. I then investigate the sub-task of modelling styled sentences without images. The specific task chosen is sentence simplification: rewriting news article sentences to make them easier to understand. For this task I design a neural sequence-to-sequence model that can work with limited training data, using novel adaptations for word copying and sharing word embeddings. Finally, I present SemStyle, a system for generating visually relevant image captions in the style of an arbitrary text corpus. A shared term space allows a neural network for vision and content planning to communicate with a network for styled language generation. SemStyle achieves competitive results in human and automatic evaluations of descriptiveness and style. As a whole, this thesis presents two complete systems for styled caption generation that are first of their kind and demonstrate, for the first time, that automatic style transfer for image captions is achievable. Contributions also include novel ideas for object naming and sentence simplification. This thesis opens up inquiries into highly personalised image captions; large scale visually grounded concept naming; and more generally, styled text generation with content control.}
}

@inproceedings{toyer2018action,
  title        = {Action Schema Networks: Generalised Policies with Deep Learning},
  author       = {Toyer, Sam and Trevizan, Felipe and Thi{\'e}baux, Sylvie and Xie, Lexing},
  booktitle    = {AAAI Conference on Artificial Intelligence (AAAI)},
  year         = {2018},
  address      = {New Orleans, USA},
  url_abstract = {https://arxiv.org/abs/1709.04271},
  url_paper    = {https://arxiv.org/pdf/1709.04271},
  url_code     = {https://github.com/qxcv/asnets}
}

@inproceedings{pmlr-v80-kim18c,
  title     = {Self-Bounded Prediction Suffix Tree via Approximate String Matching},
  author    = {Kim, Dongwoo and Walder, Christian},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning},
  pages     = {2664--2672},
  year      = {2018},
  editor    = {Dy, Jennifer and Krause, Andreas},
  volume    = {80},
  series    = {Proceedings of Machine Learning Research},
  address   = {Stockholmsmässan, Stockholm Sweden},
  month     = {10--15 Jul},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v80/kim18c/kim18c.pdf},
  url       = {http://proceedings.mlr.press/v80/kim18c.html},
  abstract  = {Prediction suffix trees (PST) provide an effective tool for sequence modelling and prediction. Current prediction techniques for PSTs rely on exact matching between the suffix of the current sequence and the previously observed sequence. We present a provably correct algorithm for learning a PST with approximate suffix matching by relaxing the exact matching condition. We then present a self-bounded enhancement of our algorithm where the depth of suffix tree grows automatically in response to the model performance on a training sequence. Through experiments on synthetic datasets as well as three real-world datasets, we show that the approximate matching PST results in better predictive performance than the other variants of PST.}
}

@inproceedings{pmlr-v80-walder18a,
  title     = {Neural Dynamic Programming for Musical Self Similarity},
  author    = {Walder, Christian and Kim, Dongwoo},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning},
  pages     = {5092--5100},
  year      = {2018},
  editor    = {Dy, Jennifer and Krause, Andreas},
  volume    = {80},
  series    = {Proceedings of Machine Learning Research},
  address   = {Stockholmsmässan, Stockholm Sweden},
  month     = {10--15 Jul},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v80/walder18a/walder18a.pdf},
  url       = {http://proceedings.mlr.press/v80/walder18a.html},
  abstract  = {We present a neural sequence model designed specifically for symbolic music. The model is based on a learned edit distance mechanism which generalises a classic recursion from computer science, leading to a neural dynamic program. Repeated motifs are detected by learning the transformations between them. We represent the arising computational dependencies using a novel data structure, the edit tree; this perspective suggests natural approximations which afford the scaling up of our otherwise cubic time algorithm. We demonstrate our model on real and synthetic data; in all cases it out-performs a strong stacked long short-term memory benchmark.}
}

@inproceedings{mathews2018semstyle,
  title        = {{SemStyle}:  Learning to Generate Stylised Image Captions using Unaligned Text},
  author       = {Mathews, Alexander and Xie, Lexing and He, Xuming},
  booktitle    = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  url_abstract = {https://arxiv.org/abs/1805.07030},
  url_paper    = {https://arxiv.org/pdf/1805.07030},
  url_code     = {https://github.com/computationalmedia/semstyle},
  address      = {Salt Lake City, USA},
  year         = {2018},
  abstract     = {Linguistic style is an essential part of written communication, with the power to affect both clarity and attractiveness. With recent advances in vision and language, we can start to tackle the problem of generating image captions that are both visually grounded and appropriately styled. Existing approaches either require styled training captions aligned to images or generate captions with low relevance. We develop a model that learns to generate visually relevant styled captions from a large corpus of styled text without aligned images. The core idea of this model, called SemStyle, is to separate semantics and style. One key component is a novel and concise semantic term representation generated using natural language processing techniques and frame semantics. In addition, we develop a unified language model that decodes sentences with diverse word choices and syntax for different styles. Evaluations, both automatic and manual, show captions from SemStyle preserve image semantics, are descriptive, and are style shifted. More broadly, this work provides possibilities to learn richer image descriptions from the plethora of linguistic data available on the web.}
}

@inproceedings{Rizoiu2018a,
  abstract     = {Serious concerns have been raised about the role of `socialbots' in manipulating public opinion and influencing the outcome of elections by retweeting partisan content to increase its reach. Here we analyze the role and influence of socialbots on Twitter by determining how they contribute to retweet diffusions. We collect a large dataset of tweets during the 1st U.S. presidential debate in 2016 and we analyze its 1.5 million users from three perspectives: user influence, political behavior (partisanship and engagement) and botness. First, we define a measure of user influence based on the user's active contributions to information diffusions, i.e. their tweets and retweets. Given that Twitter does not expose the retweet structure -- it associates all retweets with the original tweet -- we model the latent diffusion structure using only tweet time and user features, and we implement a scalable novel approach to estimate influence over all possible unfoldings. Next, we use partisan hashtag analysis to quantify user political polarization and engagement. Finally, we use the BotOrNot API to measure user botness (the likelihood of being a bot). We build a two-dimensional "polarization map" that allows for a nuanced analysis of the interplay between botness, partisanship and influence. We find that not only are socialbots more active on Twitter -- starting more retweet cascades and retweeting more -- but they are 2.5 times more influential than humans, and more politically engaged. Moreover, pro-Republican bots are both more influential and more politically engaged than their pro-Democrat counterparts. However we caution against blanket statements that software designed to appear human dominates politics-related activity on Twitter. Firstly, it is known that accounts controlled by teams of humans (e.g. organizational accounts) are often identified as bots. Secondly, we find that many highly influential Twitter users are in fact pro-Democrat and that most pro-Republican users are mid-influential and likely to be human (low botness).},
  address      = {Stanford, CA, USA},
  author       = {Rizoiu, Marian-Andrei and Graham, Timothy and Zhang, Rui and Zhang, Yifei and Ackland, Robert and Xie, Lexing},
  booktitle    = {International AAAI Conference on Web and Social Media (ICWSM '18)},
  title        = {{{\#}DebateNight: The Role and Influence of Socialbots on Twitter During the 1st 2016 U.S. Presidential Debate}},
  year         = {2018},
  url_abstract = {https://arxiv.org/abs/1802.09808},
  url_paper    = {https://arxiv.org/pdf/1802.09808.pdf},
  url_code     = {https://github.com/computationalmedia/cascade-influence},
  url_slides   = {http://www.rizoiu.eu/documents/research/presentations/RIZOIU_ICWSM-2018_slides.pdf}
}

@inproceedings{wu2018beyond,
  address      = {Stanford, CA, USA},
  author       = {Wu, Siqi and Rizoiu, Marian-Andrei and Xie, Lexing},
  booktitle    = {International AAAI Conference on Web and Social Media (ICWSM '18)},
  title        = {Beyond Views: Measuring and Predicting Engagement in Online Videos},
  year         = {2018},
  abstract     = {The share of videos in the internet traffic has been growing, therefore understanding how videos capture attention on a global scale is also of growing importance. Most current research focus on modeling the number of views, but we argue that video engagement, or time spent watching is a more appropriate measure for resource allocation problems in attention, networking, and promotion activities. In this paper, we present a first large-scale measurement of video-level aggregate engagement from publicly available data streams, on a collection of 5.3 million YouTube videos published over two months in 2016. We study a set of metrics including time and the average percentage of a video watched. We define a new metric, relative engagement, that is calibrated against video properties and strongly correlate with recognized notions of quality. Moreover, we find that engagement measures of a video are stable over time, thus separating the concerns for modeling engagement and those for popularity -- the latter is known to be unstable over time and driven by external promotions. We also find engagement metrics predictable from a cold-start setup, having most of its variance explained by video context, topics and channel information -- R2=0.77. Our observations imply several prospective uses of engagement metrics -- choosing engaging topics for video production, or promoting engaging videos in recommender systems.},
  url_abstract = {https://arxiv.org/abs/1709.02541},
  url_paper    = {http://cm.cecs.anu.edu.au/documents/wu_icwsm2018_engagement.pdf},
  url_code     = {https://github.com/avalanchesiqi/youtube-engagement},
  url_slides   = {http://cm.cecs.anu.edu.au/documents/wu_icwsm2018_slides.pdf}
}

@inproceedings{Mishra2018rnn-mas,
  address      = {Stanford, CA, USA},
  author       = {Mishra, Swapnil and Rizoiu, Marian-Andrei and Xie, Lexing},
  booktitle    = {International AAAI Conference on Web and Social Media (ICWSM '18)},
  pages        = {1--10},
  title        = {{Modeling Popularity in Asynchronous Social Media Streams with Recurrent Neural Networks}},
  year         = {2018},
  abstract     = {Understanding and predicting the popularity of online items is an important open problem in social media analysis. Considerable progress has been made recently in data-driven predictions, and in linking popularity to external promotions. However, the existing methods typically focus on a single source of external influence, whereas for many types of online content such as YouTube videos or news articles, attention is driven by multiple heterogeneous sources simultaneously - e.g. microblogs or traditional media coverage. Here, we propose RNN-MAS, a recurrent neural network for modeling asynchronous streams. It is a sequence generator that connects multiple streams of different granularity via joint inference. We show RNN-MAS not only to outperform the current state-of-the-art Youtube popularity prediction system by 17%, but also to capture complex dynamics, such as seasonal trends of unseen influence. We define two new metrics: promotion score quantifies the gain in popularity from one unit of promotion for a Youtube video; the loudness level captures the effects of a particular user tweeting about the video. We use the loudness level to compare the effects of a video being promoted by a single highly-followed user (in the top 1% most followed users) against being promoted by a group of mid-followed users. We find that results depend on the type of content being promoted: superusers are more successful in promoting Howto and Gaming videos, whereas the cohort of regular users are more influential for Activism videos. This work provides more accurate and explainable popularity predictions, as well as computational tools for content producers and marketers to allocate resources for promotion campaigns.},
  url_abstract = {https://arxiv.org/abs/1804.02101},
  url_paper    = {https://arxiv.org/pdf/1804.02101.pdf},
  url_code     = {https://github.com/computationalmedia/rnn-mas}
}

@incollection{Rizoiu2018HPE,
  author       = {Rizoiu, Marian-Andrei and Lee, Young and Mishra, Swapnil and Xie, Lexing},
  title        = {Hawkes Processes for Events in Social Media},
  booktitle    = {Frontiers of Multimedia Research},
  editor       = {Chang, Shih-Fu},
  year         = {2018},
  isbn         = {978-1-97000-107-5},
  pages        = {191--218},
  numpages     = {28},
  abstract     = {This chapter provides an accessible introduction for point processes, and especially Hawkes processes, for modeling discrete, inter-dependent events over continuous time. We start by reviewing the definitions and the key concepts in point processes. We then introduce the Hawkes process, its event intensity function, as well as schemes for event simulation and parameter estimation. We also describe a practical example drawn from social media data - we show how to model retweet cascades using a Hawkes self-exciting process. We presents a design of the memory kernel, and results on estimating parameters and predicting popularity. The code and sample event data are available as an online appendix.},
  url          = {https://doi.org/10.1145/3122865.3122874},
  url_abstract = {https://arxiv.org/abs/1708.06401},
  url_paper    = {https://arxiv.org/pdf/1708.06401.pdf},
  url_code     = {https://github.com/s-mishra/featuredriven-hawkes},
  doi          = {10.1145/3122865.3122874},
  acmid        = {3122874},
  publisher    = {Association for Computing Machinery and Morgan \& Claypool},
  address      = {New York, NY, USA}
}

@inproceedings{rizoiu2018sir,
  title        = {{SIR-Hawkes}: Linking Epidemic Models and {Hawkes} Processes to Model Diffusions in Finite Populations},
  author       = {Rizoiu, Marian-Andrei and Mishra, Swapnil and Kong, Quyu and Carman, Mark and Xie, Lexing},
  address      = {Lyon, France},
  booktitle    = {Proceedings of the 2018 World Wide Web Conference},
  series       = {WWW '18},
  year         = {2018},
  abstract     = {Among the statistical tools for online information diffusion modeling, both epidemic models and Hawkes point processes are popular choices. The former originate from epidemiology, and consider information as a viral contagion which spreads into a population of online users. The latter have roots in geophysics and finance, view individual actions as discrete events in continuous time, and modulate the rate of events according to the self-exciting nature of event sequences. Here, we establish a novel connection between these two frameworks. Namely, the rate of events in an extended Hawkes model is identical to the rate of new infections in the Susceptible-Infected-Recovered (SIR) model after marginalizing out recovery events -- which are unobserved in a Hawkes process. This result paves the way to apply tools developed for SIR to Hawkes, and vice versa. It also leads to HawkesN, a generalization of the Hawkes model which accounts for a finite population size. Finally, we derive the distribution of cascade sizes for HawkesN, inspired by methods in stochastic SIR. Such distributions provide nuanced explanations to the general unpredictability of popularity: the distribution for diffusion cascade sizes tends to have two modes, one corresponding to large cascade sizes and another one around zero.},
  doi          = {10.1145/3178876.3186108},
  eprint       = {1711.01679},
  isbn         = {9781450356398},
  pages        = {419--428},
  url_abstract = {https://arxiv.org/abs/1711.01679},
  url_paper    = {https://arxiv.org/pdf/1711.01679.pdf},
  url_code     = {https://github.com/computationalmedia/sir-hawkes},
  url_slides   = {http://www.rizoiu.eu/documents/research/presentations/RIZOIU_WWW-2018_slides.pdf}
}

@inproceedings{kong2018will,
  title        = {Will This Video Go Viral? Explaining and Predicting the Popularity of Youtube Videos},
  author       = {Kong, Quyu and Rizoiu, Marian-Andrei and Wu, Siqi and Xie, Lexing},
  address      = {Lyon, France},
  booktitle    = {Companion Proceedings of the The Web Conference 2018 - Demos},
  series       = {WWW '18},
  year         = {2018},
  abstract     = {What makes content go viral? Which videos become popular and why others don't? Such questions have elicited significant attention from both researchers and industry, particularly in the context of online media. A range of models have been recently proposed to explain and predict popularity; however, there is a short supply of practical tools, accessible for regular users, that leverage these theoretical results. Hipie -- an interactive visualization system -- is created to fill this gap, by enabling users to reason about the virality and the popularity of online videos. It retrieves the metadata and the past popularity series of Youtube videos, it employs the Hawkes Intensity Process, a state-of-the-art online popularity model for explaining and predicting video popularity, and it presents videos comparatively in a series of interactive plots. This system will help both content consumers and content producers in a range of data-driven inquiries, such as to comparatively analyze videos and channels, to explain and to predict future popularity, to identify viral videos, and to estimate responses to online promotion. },
  doi          = {10.1145/3184558.3186972},
  url_abstract = {https://arxiv.org/abs/1801.04117},
  url_paper    = {https://arxiv.org/pdf/1801.04117.pdf},
  url_code     = {https://github.com/computationalmedia/hipie}
}

@inproceedings{toyer2018action,
  title        = {Action Schema Networks: Generalised Policies with Deep Learning},
  author       = {Toyer, Sam and Trevizan, Felipe and Thi{\'e}baux, Sylvie and Xie, Lexing},
  booktitle    = {AAAI Conference on Artificial Intelligence (AAAI)},
  year         = {2018},
  address      = {New Orleans, USA},
  abstract     = {In this paper, we introduce the Action Schema Network (ASNet): a neural network architecture for learning generalised policies for probabilistic planning problems. By mimicking the relational structure of planning problems, ASNets are able to adopt a weight-sharing scheme which allows the network to be applied to any problem from a given planning domain. This allows the cost of training the network to be amortised over all problems in that domain. Further, we propose a training method which balances exploration and supervised training on small problems to produce a policy which remains robust when evaluated on larger problems. In experiments, we show that ASNet's learning capability allows it to significantly outperform traditional non-learning planners in several challenging domains.},
  url_abstract = {https://arxiv.org/abs/1709.04271},
  url_paper    = {https://arxiv.org/pdf/1709.04271},
  url_code     = {https://github.com/qxcv/asnets}
}

@inproceedings{zhao2018analyzing,
  title        = {Analyzing and Predicting Emoji Usages in Social Media},
  author       = {Zhao, Peijun and Jia, Jia and An, Yongsheng and Liang, Jie and Xie, Lexing and Luo, Jiebo},
  booktitle    = {Companion of the The Web Conference 2018 on The Web Conference 2018 -- Cognitive Computing Track},
  pages        = {327--334},
  year         = {2018},
  organization = {International World Wide Web Conferences Steering Committee},
  abstract     = {Emojis can be regarded as a language for graphical expression of emotions, and have been widely used in social media. They can express more delicate feelings beyond textual information and improve the effectiveness of computer-mediated communication. Recent advances in machine learning make it possible to automatic compose text messages with emojis. However, the usages of emojis can be complicated and subtle so that analyzing and predicting emojis is a challenging problem. In this paper, we first construct a benchmark dataset of emojis with tweets and systematically investigate emoji usages in terms of tweet content, tweet structure and user demographics. Inspired by the investigation results, we further propose a multitask multimodality gated recurrent unit (mmGRU) model to predict the categories and positions of emojis. The model leverages not only multimodality information such as text, image and user demographics, but also the strong correlations between emoji categories and their positions. Our experimental results show that the proposed method can significantly improve the accuracy for predicting emojis for tweets (+9.0% in F1-value for category and +4.6% in F1-value for position). Based on the experimental results, we further conduct a series of case studies to unveil how emojis are used in social media.},
  url          = {https://doi.org/10.1145/3184558.3186344},
  doi          = {10.1145/3184558.3186344},
  url_paper    = {http://cm.cecs.anu.edu.au/documents/zhao-emoji-2018.pdf}
}

@inproceedings{Jin2017hcomp,
  address   = {Quebec, Canada},
  author    = {Yuan Jin and Mark Carman and Dongwoo Kim and Lexing Xie},
  booktitle = {The AAAI Conference on Human Computation and Crowdsourcing (HCOMP)},
  title     = {Leveraging Side Information to Improve Crowd-sourcing},
  year      = {2017},
  abstract  = {We investigate the possibility of leveraging side information for improving quality control over crowd-sourced data. We extend the GLAD model, which governs the probability of correct labeling through a logistic function in which worker expertise counteracts item difficulty, by systematically encod- ing different types of side information, including worker in- formation drawn from demographics and personality traits, item information drawn from item genres and content, and contextual information drawn from worker responses and la- beling sessions. Modeling side information allows for better estimation of worker expertise and item difficulty in sparse data situations and accounts for worker biases, leading to bet- ter prediction of posterior true label probabilities. We demon- strate the efficacy of the proposed framework with overall improvements in both the true label prediction and the un- seen worker response prediction based on different combina- tions of the various types of side information across three new crowd-sourcing datasets. In addition, we show the framework exhibits potential of identifying salient side information fea- tures for predicting the correctness of responses without the need of knowing any true label information.},
  url_paper = {https://aaai.org/ocs/index.php/HCOMP/HCOMP17/paper/view/15940/15265}
}

@inproceedings{chen2017structrec,
  author    = {Dawei Chen and Lexing Xie and Aditya Krishna Menon and Cheng Soon Ong},
  booktitle = {Arxiv preprint},
  title     = {Structured Recommendation},
  year      = {2017},
  abstract  = {Current recommender systems largely focus on static, unstructured content. In many scenarios, we would like to recommend content that has structure, such as a trajectory of points-of-interests in a city, or a playlist of songs. Dubbed Structured Recommendation, this problem differs from the typical structured prediction problem in that there are multiple correct answers for a given input. Motivated by trajectory recommendation, we focus on sequential structures but in contrast to classical Viterbi decoding we require that valid predictions are sequences with no repeated elements. We propose an approach to sequence recommendation based on the structured support vector machine. For prediction, we modify the inference procedure to avoid predicting loops in the sequence. For training, we modify the objective function to account for the existence of multiple ground truths for a given input. We also modify the loss-augmented inference procedure to exclude the known ground truths. Experiments on real-world trajectory recommendation datasets show the benefits of our approach over existing, non-structured recommendation approaches.},
  url_paper = {https://arxiv.org/pdf/1706.09067}
}

@inproceedings{chen2017recsys,
  address   = {Como, Italy},
  author    = {Dawei Chen and Dongwoo Kim and Lexing Xie and Minjeong Shin and Aditya Krishna Menon and Cheng Soon Ong and Iman Avazpour and John Grundy},
  booktitle = {The ACM Recommender Systems conference (RecSys) Demo},
  title     = {PathRec: Visual Analysis of Travel Route Recommendations},
  year      = {2017},
  doi       = {10.1145/3109859.3109983},
  isbn      = {978-1-4503-4652-8/17/08},
  abstract  = {We present an interactive visualisation tool for recommending travel trajectories. This system is based on new machine learning formulations and algorithms for the sequence recommendation problem. The system starts from a map-based overview, taking an interactive query as starting point. It then breaks down contributions from different geographical and user behavior features, and those from individual points-of-interest versus pairs of consecutive points on a route. The system also supports detailed quantitative interrogation by comparing a large number of features for multiple points. Effective trajectory visualisations can potentially benefit a large cohort of online map users and assist their decision-making. More broadly, the design of this system can inform visualisations of other structured prediction tasks, such as for sequences or trees.},
  url_paper = {http://cm.cecs.anu.edu.au/documents/chen_recsys2017_demo.pdf}
}

@inproceedings{chen2017citrec,
  address   = {Como, Italy},
  author    = {Aditya Krishna Menon and Dawei Chen and Lexing Xie and Cheng Soon Ong},
  booktitle = {International Workshop on Recommender Systems for Citizens (CitRec)},
  title     = {Revisiting revisits in trajectory recommendation},
  year      = {2017},
  doi       = {10.1145/3127325.3127326},
  isbn      = {978-1-4503-5370-0/17/08},
  abstract  = {Trajectory recommendation is the problem of recommending a sequence of places in a city for a tourist to visit. It is strongly desirable for the recommended sequence to avoid loops, as tourists typically would not wish to revisit the same location. Given some learned model that scores sequences, how can we then find the highest-scoring sequence that is loop-free? This paper studies this problem, with three contributions. First, we detail three distinct approaches to the problem -- graph-based heuristics, integer linear programming, and list extensions of the Viterbi algorithm -- and qualitatively summarise their strengths and weaknesses. Second, we explicate how two ostensibly different approaches to the list Viterbi algorithm are in fact fundamentally identical. Third, we conduct experiments on real-world trajectory recommendation datasets to identify the tradeoffs imposed by each of the three approaches. Overall, our results indicate that a greedy graph-based heuristic offer excellent performance and runtime, leading us to recommend its use for removing loops at prediction time.},
  url_paper = {http://cm.cecs.anu.edu.au/documents/chen_citrec2017_workshop.pdf}
}

@inproceedings{Rizoiu2017HIP,
  address      = {Perth, Australia},
  author       = {Rizoiu, Marian-Andrei and Xie, Lexing and Sanner, Scott and Cebrian, Manuel and Yu, Honglin and {Van Hentenryck}, Pascal},
  booktitle    = {World Wide Web 2017, International Conference on},
  pages        = {735--744},
  title        = {Expecting to be {HIP}: Hawkes Intensity Processes for Social Media Popularity},
  year         = {2017},
  doi          = {10.1145/3038912.3052650},
  isbn         = {9781450349130},
  abstract     = {Modeling and predicting the popularity of online content is a significant problem for the practice of information dissemination, advertising, and consumption. Recent work analyzing massive datasets advances our understanding of popularity, but one major gap remains: To precisely quantify the relationship between the popularity of an online item and the external promotions it receives. This work supplies the missing link between exogenous inputs from public social media platforms, such as Twitter, and endogenous responses within the content platform, such as YouTube. We develop a novel mathematical model, the Hawkes intensity process, which can explain the complex popularity history of each video according to its type of content, network of diffusion, and sensitivity to promotion. Our model supplies a prototypical description of videos, called an endo-exo map. This map explains popularity as the result of an extrinsic factor -- the amount of promotions from the outside world that the video receives, acting upon two intrinsic factors -- sensitivity to promotion, and inherent virality. We use this model to forecast future popularity given promotions on a large 5-months feed of the most-tweeted videos, and found it to lower the average error by 28.6% from approaches based on popularity history. Finally, we can identify videos that have a high potential to become viral, as well as those for which promotions will have hardly any effect.},
  url_abstract = {https://arxiv.org/abs/1602.06033},
  url_paper    = {https://arxiv.org/pdf/1602.06033}
}

@inproceedings{Rizoiu2017promo,
  address      = {Montreal, Canada},
  author       = {Rizoiu, Marian-Andrei and Xie, Lexing},
  booktitle    = {The International AAAI Conference on Web and Social Media (ICWSM)},
  pages        = {1--10},
  title        = {Online Popularity under Promotion: Viral Potential, Forecasting, and the Economics of Time},
  year         = {2017},
  abstract     = {Modeling the popularity dynamics of an online item is an important open problem in computational social science. This paper presents an in-depth study of popularity dynamics under external promotions, especially in predicting popularity jumps of online videos, and determining effective and efficient schedules to promote online content. The recently-proposed Hawkes Intensity Process (HIP) models popularity as a non-linear interplay between exogenous stimuli and the endogenous reaction. We propose two novel metrics based on HIP: to describe popularity gain per unit of promotion, and to quantify the time it takes for such effects to unfold. We make increasingly accurate forecasts of future popularity by including information about the intrinsic properties of the video, promotions it receives, and the non-linear effects of popularity ranking. We illustrate by simulation the interplay between the unfolding of popularity over time, and the time-sensitive value of resources. Lastly, our model lends a novel explanation of the commonly adopted periodic and constant promotion strategy in advertising, as increasing the perceived viral potential. This study provides quantitative guidelines about setting promotion schedules considering content virality, timing, and economics.},
  url_abstract = {https://arxiv.org/abs/1703.01012},
  url_paper    = {https://arxiv.org/pdf/1703.01012}
}

@inproceedings{sanner:icwsm17,
  author       = {Zahra Iman and Scott Sanner and Mohamed Reda Bouadjenek and Lexing Xie},
  year         = {2017},
  title        = {A Longitudinal Study of Topic Classification on Twitter},
  booktitle    = {Proceedings of the 11th International AAAI Conference on Web and Social Media ({ICWSM-17})},
  url_abstract = {https://aaai.org/ocs/index.php/ICWSM/ICWSM17/paper/view/15625},
  url_paper    = {https://aaai.org/ocs/index.php/ICWSM/ICWSM17/paper/download/15625/14852}
}

@inproceedings{sedhain2017loco,
  address      = {San Francisco, USA},
  author       = {Suvash Sedhain and Aditya Krishna Menon and Scott Sanner and Lexing Xie and Darius Braziunas},
  booktitle    = {AAAI Conference on Artificial Intelligence (AAAI)},
  title        = {Low-rank linear cold-start recommendation from social data},
  year         = {2017},
  abstract     = {The cold-start problem involves recommendation of content to new users of a system, for whom there is no historical preference information available. This proves a challenge for collaborative filtering algorithms that inherently rely on such information. Recent work has shown that social metadata, such as users' friend groups and page likes, can strongly mitigate the problem. However, such approaches either lack an interpretation as optimising some principled objective, involve iterative non-convex optimisation with limited scalability, or require tuning several hyperparameters. In this paper, we first show how three popular cold-start models are special cases of a linear content-based model, with implicit constraints on the weights. Leveraging this insight, we propose Loco, a new model for cold-start recommendation based on three ingredients: (a) linear regression to learn an optimal weighting of social signals for preferences, (b) a low-rank parametrisation of the weights to overcome the high dimensionality common in social data, and (c) scalable learning of such low-rank weights using randomised SVD. Experiments on four real-world datasets show that Loco yields significant improvements over state-of-the-art cold-start recommenders that exploit high-dimensional social network metadata.},
  url_abstract = {https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14828},
  url_paper    = {http://cm.cecs.anu.edu.au/documents/loco-aaai17-final.pdf}
}



@inproceedings{Mishra2016,
  title                 = {{Feature Driven and Point Process Approaches for Popularity Prediction}},
  author                = {Mishra, Swapnil and Rizoiu, Marian-Andrei and Xie, Lexing},
  booktitle             = {Proceedings of the 25th ACM International Conference on Information and Knowledge Management},
  series                = {CIKM '16},
  address               = {Indianapolis, IN, USA},
  doi                   = {10.1145/2983323.2983812},
  keywords              = {social media; self-exciting point process; information diffusion; cascade prediction},
  year                  = {2016},
  abstract              = {Predicting popularity, or the total volume of information outbreaks, is an important subproblem for understanding collective behavior in networks. Each of the two main types of recent approaches to the problem, feature-driven and generative models, have desired qualities and clear limitations. This paper bridges the gap between these solutions with a new hybrid approach and a new performance benchmark. We model each social cascade with a marked Hawkes self-exciting point process, and estimate the content virality, memory decay, and user influence. We then learn a predictive layer for popularity prediction using a collection of cascade history. To our surprise, Hawkes process with a predictive overlay outperform recent feature-driven and generative approaches on existing tweet data [44] and a new public benchmark on news tweets. We also found that a basic set of user features and event time summary statistics performs competitively in both classification and regression tasks, and that adding point process information to the feature set further improves predictions. From these observations, we argue that future work on popularity prediction should compare across feature-driven and generative modeling approaches in both classification and regression tasks.},
  url_abstract          = {https://arxiv.org/abs/1608.04862},
  url_paper             = {https://arxiv.org/pdf/1608.04862.pdf},
  url_presentation_page = {http://cm.cecs.anu.edu.au/post/fdhawkesforpopularity/},
  url_slides            = {http://cm.cecs.anu.edu.au/documents/smishra_cikm16_presentation.pdf}
}


@inproceedings{kim2016,
  title                 = {{Probabilistic Knowledge Graph Construction: Compositional and Incremental Approaches}},
  author                = {Kim, Dongwoo and Xie, Lexing and Ong, Cheng Soon},
  booktitle             = {Proceedings of the 25th ACM International Conference on Information and Knowledge Management},
  series                = {CIKM '16},
  address               = {Indianapolis, IN, USA},
  doi                   = {10.1145/2983323.2983677},
  keywords              = {Knowledge graph, active learning, Thompson sampling},
  year                  = {2016},
  url_abstract          = {http://arxiv.org/abs/1608.05921},
  url_paper             = {http://arxiv.org/pdf/1608.05921.pdf},
  url_presentation_page = {http://cm.cecs.anu.edu.au/post/kg_construction_cikm16/},
  url_slides            = {http://cm.cecs.anu.edu.au/documents/kim_cikm16_slides.pdf},
  abstract              = {Knowledge graph construction consists of two tasks: extracting information from external resources (knowledge population) and inferring missing information through a statistical analysis on the extracted information (knowledge completion). In many cases, insufficient external resources in the knowledge population hinder the subsequent statistical inference. The gap between these two processes can be reduced by an incremental population approach. We propose a new probabilistic knowledge graph factorisation method that benefits from the path structure of existing knowledge (e.g. syllogism) and enables a common modelling approach to be used for both incremental population and knowledge completion tasks. More specifically, the probabilistic formulation allows us to develop an incremental population algorithm that trades off exploitation-exploration. Experiments on three benchmark datasets show that the balanced exploitation-exploration helps the incremental population, and the additional path structure helps to predict missing information in knowledge completion.}
}


@inproceedings{chen2016,
  title                 = {{Learning Points and Routes to Recommend Trajectories}},
  author                = {Chen, Dawei and Ong, Cheng Soon and Xie, Lexing},
  booktitle             = {Proceedings of the 25th ACM International Conference on Information and Knowledge Management},
  series                = {CIKM '16},
  address               = {Indianapolis, IN, USA},
  doi                   = {10.1145/2983323.2983672},
  keywords              = {Trajectory recommendation; learning to rank; planning},
  year                  = {2016},
  url_abstract          = {http://arxiv.org/abs/1608.07051},
  url_paper             = {http://arxiv.org/pdf/1608.07051.pdf},
  url_presentation_page = {http://cm.cecs.anu.edu.au/post/trajrec_cikm16/},
  url_poster            = {http://cm.cecs.anu.edu.au/documents/chen_cikm16_poster.pdf},
  abstract              = {The problem of recommending tours to travellers is an important and broadly studied area. Suggested solutions include various approaches of points-of-interest (POI) recommendation and route planning. We consider the task of recommending a sequence of POIs, that simultaneously uses information about POIs and routes. Our approach unifies the treatment of various sources of information by representing them as features in machine learning algorithms, enabling us to learn from past behaviour. Information about POIs are used to learn a POI ranking model that accounts for the start and end points of tours. Data about previous trajectories are used for learning transition patterns between POIs that enable us to recommend probable routes. In addition, a probabilistic model is proposed to combine the results of POI ranking and the POI to POI transitions. We propose a new F1 score on pairs of POIs that capture the order of visits. Empirical results show that our approach improves on recent methods, and demonstrate that combining points and routes enables better trajectory recommendations.}
}


@inproceedings{Rizoiu2016,
  abstract              = {The cumulative effect of collective participation online has an important and adverse impact on individual privacy. As an online system evolves over time, new digital traces of individual behavior may uncover previously hidden statistical links between an individual’s past actions and her private traits. Furthermore, this de-anonymization trend may not be observable when analyzing short or medium time-span snapshots of data. To quantify this effect, we analyze the evolution of individual privacy loss by studying the 13-year long edit history of Wikipedia, including more than 117,523 different users performing 188,805,088 edits. We trace each Wikipedia’s contributor using apparently harmless features, such as the number of edits performed on predefined broad categories in a given time period (e.g. Mathematics, Culture or Nature). We show that even at this unspecific level of identification, it is possible to use off-the-shelf machine learning algorithms to uncover usually undisclosed private traits, such as gender, religion or education. We provide empirical evidence that the prediction accuracy for almost all private traits consistently improves over time. Moreover, we observe that the system also shows improved prediction for users who participated in the system during “safe” periods — periods where a given individual’s private traits could not be — showing that de-anonymization threats are hard to foresee as online systems evolve. Insights from this work should help users, system designers, and policy makers understand and debate the design and long-term effects of online content creation systems.},
  address               = {San Francisco, CA, USA},
  author                = {Rizoiu, Marian-Andrei and Xie, Lexing and Caetano, Tiberio and Cebrian, Manuel},
  booktitle             = {Proceedings of the 9th ACM International Conference on Web Search and Data Mining},
  series                = {WSDM '16},
  doi                   = {10.1145/2835776.2835798},
  keywords              = {de-anonymization,online privacy,temporal loss of privacy},
  title                 = {{Evolution of Privacy Loss on Wikipedia}},
  year                  = {2016},
  url_paper             = {http://arxiv.org/pdf/1512.03523.pdf},
  url_presentation_page = {http://cm.cecs.anu.edu.au/post/wikiprivacy/}
}

@inproceedings{mathews2016senticap,
  title        = {{SentiCap: Generating Image Descriptions with Sentiments}},
  author       = {Mathews, Alexander and Xie, Lexing and He, Xuming},
  booktitle    = {Thirtieth {AAAI} Conference on Artificial Intelligence ({AAAI-16})},
  url_abstract = {http://arxiv.org/abs/1510.01431},
  url_paper    = {http://arxiv.org/pdf/1510.01431v2.pdf},
  url_slides   = {http://cm.cecs.anu.edu.au/documents/senticap_slides.pdf},
  address      = {Phoenix, Arizona USA},
  year         = {2016},
  abstract     = {The recent progress on image recognition and language modeling is making automatic description of image content a reality. However, stylized, non-factual aspects of the written description are missing from the current systems. One such style is descriptions with emotions, which is commonplace in everyday communication, and influences decision-making and interpersonal relationships. We design a system to describe an image with emotions, and present a model that automatically generates captions with positive or negative sentiments. We propose a novel switching recurrent neural network with word-level regularization, which is able to produce emotional image captions using only 2000+ training sentences containing sentiments. We evaluate the captions with different automatic and crowd-sourcing metrics. Our model compares favourably in common quality metrics for image captioning. In 84.6\% of cases the generated positive captions were judged as being at least as descriptive as the factual captions. Of these positive captions 88\% were confirmed by the crowd-sourced workers as having the appropriate sentiment.}
}


@article{butt2016dwrank,
  title        = {DWRank: Learning concept ranking for ontology search},
  author       = {Butt, Anila Sahar and Haller, Armin and Xie, Lexing},
  journal      = {Semantic Web},
  volume       = {7},
  number       = {4},
  pages        = {447--461},
  year         = {2016},
  publisher    = {IOS Press},
  url_abstract = {http://www.semantic-web-journal.net/content/dwrank-learning-concept-ranking-ontology-search},
  url_paper    = {http://www.semantic-web-journal.net/system/files/swj883.pdf}
}

@article{butt2016recon,
  title        = {RecOn: Ontology recommendation for structureless queries},
  author       = {Butt, Anila Sahar and Haller, Armin and Xie, Lexing},
  journal      = {Applied Ontology},
  volume       = {11},
  number       = {4},
  pages        = {301--324},
  year         = {2016},
  publisher    = {IOS Press},
  url_abstract = {http://content.iospress.com/articles/applied-ontology/ao173},
  url_paper    = {https://www.researchgate.net/profile/Armin_Haller/publication/310426804_RecOn_Ontology_Recommendation_for_Structureless_Queries/links/59193af4aca27200fe52f914/RecOn-Ontology-Recommendation-for-Structureless-Queries.pdf}
}

@article{liu2016interactive,
  title        = {An interactive {SpiralTape} video summarization},
  author       = {Liu, Yong-Jin and Ma, Cuixia and Zhao, Guozhen and Fu, Xiaolan and Wang, Hongan and Dai, Guozhong and Xie, Lexing},
  journal      = {IEEE Transactions on Multimedia},
  volume       = {18},
  number       = {7},
  pages        = {1269--1282},
  year         = {2016},
  publisher    = {IEEE},
  url_abstract = {http://ieeexplore.ieee.org/abstract/document/7457275/}
}

@phdthesis{yu2015understanding,
  author    = {Yu, Honglin},
  title     = {Understanding the Popularity Evolution of Online Media: A Case Study on YouTube Videos},
  publisher = {The Australian National University},
  year      = {2015},
  month     = {8},
  url_paper = {http://cm.cecs.anu.edu.au/documents/yu_dissertation.pdf},
  abstract  = {Understanding the popularity evolution of online media has become an important research topic. There are a number of key questions which have high scientific significance and wide practical relevance. In particular, what are the statistical characteristics of online user behaviors? What are the main factors that affect online collective attention? How can one predict the popularity of online content? Recently, researchers have tried to understand the way popularity evolves from both a theoretical and empirical perspective. A number of important insights have been gained: e.g., most videos obtain the majority of their viewcounts at the early stage after uploading; for videos having identical content, there is a strong “first-mover” advantage, so that early uploads have the most views; YouTube video viewcount dynamics strongly correlate with video quality. Building upon these insights, the main contributions of the thesis are: we proposed two new representations of viewcount dynamics. One is popularity scale where we represent each video’s popularity by their relative viewcount ranks in a large scale dataset. The other is the popularity phase which models the rise and fall of video’s daily viewcount overtime; We also proposed four computational tools. The first is an efficient viewcount phase detection algorithm which not only automatically determines the number of phases each video has, but also finds the phase parameters and boundaries. The second is a phase-aware viewcount prediction method which utilizes phase information to significantly improve the existing state-of-the-art method. The third is a phase-aware viewcount clustering method which can better capture “pulse patterns” in viewcount data. The fourth is a novel method of predicting viewcounts using external information from the Twitter network. Finally, this thesis sets out results from large-scale, longitudinal measurement study of YouTube video viewcount history, e.g. we find videos with different popularity and categories have distinctive phase histories. And we also observed a non-trivial number of concave phases. Dynamics like this can not be explained in terms of existing models, and the terminology and tools introduced here have the potential to spark fresh analysis efforts and further research. In all, the methods and insights developed in the thesis improve our understanding of online collective attention. They also have considerable potential usage in online marketing, recommendation and information dissemination e.g., in emergency & natural disasters.}
}

@inproceedings{sedhain2015autorec,
  title        = {Autorec: Autoencoders meet collaborative filtering},
  author       = {Sedhain, Suvash and Menon, Aditya Krishna and Sanner, Scott and Xie, Lexing},
  booktitle    = {Proceedings of the 24th International Conference on World Wide Web},
  pages        = {111--112},
  year         = {2015},
  abstract     = {This paper proposes AutoRec, a novel autoencoder framework for collaborative filtering (CF). Empirically, AutoRec's compact and efficiently trainable model outperforms state-of-the-art CF techniques (biased matrix factorization, RBM-CF and LLORMA) on the Movielens and Netflix datasets.},
  url_paper    = {http://users.cecs.anu.edu.au/~akmenon/papers/autorec/autorec-paper.pdf},
  organization = {ACM}
}

@inproceedings{mathews2015captioning,
  title        = {{Captioning Images Using Different Styles}},
  author       = {Mathews, Alexander Patrick},
  booktitle    = {Proceedings of the 23rd Annual {ACM} Conference on Multimedia Conference (Doctoral Symposium)},
  pages        = {665--668},
  year         = {2015},
  organization = {ACM},
  abstract     = {I develop techniques that can be used to incorporate stylistic objectives into existing image captioning systems. Style is generally a very tricky concept to define, thus I concentrate on two specific components of style. First I develop a technique for predicting how people will name visual objects. I demonstrate that this technique could be used to generate captions with human like naming conventions. Full details are available in a recent publication. Second I outline a system for generating sentences which express a strong positive or negative sentiment. Finally I present two possible future directions which are aimed at modelling style more generally. These are learning to imitate an individuals captioning style and generating a diverse set of captions for a single image.},
  url_paper    = {http://cm.cecs.anu.edu.au/documents/mathews2015captioning.pdf}
}

@inproceedings{yu2015lifecyle,
  title                 = {{The Lifecyle of a Youtube Video: Phases, Content and Popularity}},
  author                = {Yu, Honglin and Xie, Lexing and Sanner, Scott},
  booktitle             = {Ninth International {AAAI} Conference on Web and Social Media},
  pages                 = {10pp},
  year                  = {2015},
  abstract              = {This paper proposes a new representation to explain and predict popularity evolution in social media. Recent work on social networks has led to insights about the popularity of a digital item. For example, both the content and the network matters, and gaining early popularity is critical. However, these observations did not paint a full picture of popularity evolution; some open questions include: what kind of popularity trends exist among different types of videos, and will an unpopular video become popular? To this end, we propose a novel phase representation that extends the well-known endogenous growth and exogenous shock model (Crane and Sornette 2008). We further propose efficient algorithms to simultaneously estimate and segment power-law shaped phases from historical popularity data. With the extracted phases, we found that videos go through not one, but multiple stages of popularity increase or decrease over many months. On a dataset containing the 2-year history of over 172,000 YouTube videos, we observe that phases are directly related to content type and popularity change, e.g., nearly 3/4 of the top 5\% popular videos have 3 or more phases, more than 60\% news videos are dominated by one long power-law decay, and 75\% of videos that made a significant jump to become the most popular videos have been in increasing phases. Finally, we leverage this phase representation to predict future viewcount gain and found that using phase information reduces the average prediction error over the state-of-the-art for videos of all phase shapes.},
  url_paper             = {http://users.cecs.anu.edu.au/~xlx/papers/icwsm15-phase.pdf},
  url_slides            = {http://users.cecs.anu.edu.au/~xlx/papers/icwsm15-slides.pdf},
  url_presentation_page = {https://github.com/yuhonglin/ytphasedata}
}

@article{chen2015differential,
  title     = {{Differential Topic Models}},
  author    = {Chen, Changyou and Buntine, Wray and Ding, Nan and Xie, Lexing and Du, Lan},
  journal   = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
  volume    = {37},
  number    = {2},
  pages     = {230--242},
  year      = {2015},
  doi       = {10.1109/TPAMI.2014.2313127},
  publisher = {IEEE},
  abstract  = {In applications we may want to compare different document collections: they could have shared content but also different and unique aspects in particular collections. This task has been called comparative text mining or cross-collection modeling. We present a differential topic model for this application that models both topic differences and similarities. For this we use hierarchical Bayesian nonparametric models. Moreover, we found it was important to properly model power-law phenomena in topic-word distributions and thus we used the full Pitman-Yor process rather than just a Dirichlet process. Furthermore, we propose the transformed Pitman-Yor process (TPYP) to incorporate prior knowledge such as vocabulary variations in different collections into the model. To deal with the non-conjugate issue between model prior and likelihood in the TPYP, we thus propose an efficient sampling algorithm using a data augmentation technique based on the multinomial theorem. Experimental results show the model discovers interesting aspects of different collections. We also show the proposed MCMC based algorithm achieves a dramatically reduced test perplexity compared to some existing topic models. Finally, we show our model outperforms the state-of-the-art for document classification/ideology prediction on a number of text collections.},
  url_paper = {http://users.cecs.anu.edu.au/~xlx/papers/diffTM_PAMI.pdf}
}

@inproceedings{mathews2015choosing,
  title        = {{Choosing Basic-Level Concept Names using Visual and Language Context}},
  author       = {Mathews, Alexander and Xie, Lexing and He, Xuming},
  booktitle    = {Applications of Computer Vision (WACV), 2015 IEEE Winter Conference on},
  pages        = {595--602},
  year         = {2015},
  organization = {IEEE},
  abstract     = {We study basic-level categories for describing visual concepts, and empirically observe context-dependant basic level names across thousands of concepts. We propose methods for predicting basic-level names using a series of classification and ranking tasks, producing the first large scale catalogue of basic-level names for hundreds of thousands of images depicting thousands of visual concepts. We also demonstrate the usefulness of our method with a picture-to-word task, showing strong improvement over recent work by Ordonez et al, by modeling of both visual and language context. Our study suggests that a model for naming visual concepts is an important part of any automatic image/video captioning and visual story-telling system.},
  url_paper    = {http://users.cecs.anu.edu.au/~xlx/papers/wacv2015.pdf}
}

@article{wangmodeling,
  author    = {Xiaohui Wang and Jia Jia and Jie Tang and Boya Wu and Lianhong Cai and Lexing Xie},
  journal   = {Affective Computing, IEEE Transactions on},
  title     = {{Modeling Emotion Influence in Image Social Networks}},
  year      = {2015},
  volume    = {6},
  number    = {3},
  pages     = {286-297},
  doi       = {10.1109/TAFFC.2015.2400917},
  issn      = {1949-3045},
  month     = {July},
  abstract  = {We study emotion influence in large image social networks. We focus on users’ emotions reflected by images that they have uploaded and social influence that plays a role in changing users’ emotions. We first verify the existence of emotion influence in the image networks, and then propose a probabilistic factor graph based emotion influence model to answer the questions of "who influences whom". Employing a real network from Flickr as the basis in our empirical study, we evaluate the effectiveness of different factors in the proposed model with in-depth data analysis. The learned influence is fundamental for social network analysis and can be applied to many applications. We consider using the influence to help predict users’ emotions and our experiments can significantly improve the prediction accuracy (3.0\%-26.2\%) over several alternative methods such as Naive Bayesian, SVM (Support Vector Machine) or traditional Graph Model. We further examine the behavior of the emotion influence model, and find that more social interactions correlate with higher emotion influence between two users, and the influence of negative emotions is stronger than positive ones.},
  url_paper = {https://www.computer.org/csdl/trans/ta/preprint/07035025.pdf}
}

@inproceedings{sanner:pakdd15,
  author    = {K.{-}N. Tran and P. Christen and S. Sanner and L. Xie},
  title     = {Context-Aware Detection of Sneaky Vandalism on Wikipedia Across Multiple Languages},
  booktitle = {Advances in Knowledge Discovery and Data Mining - 19th Pacific-Asia Conference {(PAKDD-15)}},
  address   = {Ho Chi Minh City, Vietnam},
  note      = {Recipient of the Best Student Paper Award.},
  pages     = {380--391},
  year      = {2015}
}


@inproceedings{Yu:2014:TYV:2647868.2655037,
  author    = {Yu, Honglin and Xie, Lexing and Sanner, Scott},
  title     = {{Twitter-driven YouTube Views: Beyond Individual Influencers}},
  booktitle = {Proceedings of the 22Nd ACM International Conference on Multimedia},
  series    = {MM '14},
  year      = {2014},
  isbn      = {978-1-4503-3063-3},
  location  = {Orlando, Florida, USA},
  pages     = {869--872},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2647868.2655037},
  doi       = {10.1145/2647868.2655037},
  acmid     = {2655037},
  publisher = {ACM},
  address   = {New York, NY, USA},
  keywords  = {popularity prediction, social media, twitter, youtube},
  abstract  = {This paper proposes a novel method to predict increases in YouTube viewcount driven from the Twitter social network. Specifically, we aim to predict two types of viewcount increases: a sudden increase in viewcount (named as Jump), and the viewcount shortly after the upload of a new video (named as Early). Experiments on hundreds of thousands of videos and millions of tweets show that Twitter-derived features alone can predict whether a video will be in the top 5\% for Early popularity with 0.7 Precision@100. Furthermore, our results reveal that while individual influence is indeed important for predicting how Twitter drives YouTube views, it is a diversity of interest from the most active to the least active Twitter users mentioning a video (measured by the variation in their total activity) that is most informative for both Jump and Early prediction. In summary, by going beyond features that quantify individual influence and additionally leveraging collective features of activity variation, we are able to obtain an effective cross-network predictor of Twitter-driven YouTube views.},
  url_paper = {http://users.cecs.anu.edu.au/~xlx/papers/acmmm14.pdf}
}

@inproceedings{Sedhain:2014:SCF:2645710.2645772,
  author    = {Sedhain, Suvash and Sanner, Scott and Braziunas, Darius and Xie, Lexing and Christensen, Jordan},
  title     = {{Social Collaborative Filtering for Cold-start Recommendations}},
  booktitle = {Proceedings of the 8th ACM Conference on Recommender Systems},
  series    = {RecSys '14},
  year      = {2014},
  isbn      = {978-1-4503-2668-1},
  location  = {Foster City, Silicon Valley, California, USA},
  pages     = {345--348},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2645710.2645772},
  doi       = {10.1145/2645710.2645772},
  acmid     = {2645772},
  publisher = {ACM},
  address   = {New York, NY, USA},
  keywords  = {cold-start problem, recommender systems},
  abstract  = {We examine the cold-start recommendation task in an online retail setting for users who have not yet purchased (or interacted in a meaningful way with) any available items but who have granted access to limited side information, such as basic demographic data (gender, age, location) or social network information (Facebook friends or page likes). We formalize neighborhood-based methods for cold-start collaborative filtering in a generalized matrix algebra framework that does not require purchase data for target users when their side information is available. In real-data experiments with 30,000 users who purchased 80,000+ books and had 9,000,000+ Facebook friends and 6,000,000+ page likes, we show that using Facebook page likes for cold-start recommendation yields up to a 3-fold improvement in mean average precision (mAP) and up to 6-fold improvements in Precision@k and Recall@k compared to most-popular-item, demographic, and Facebook friend cold-start recommenders. These results demonstrate the substantial predictive power of social network content, and its significant utility in a challenging problem - recommendation for cold-start users.},
  url_paper = {http://users.cecs.anu.edu.au/~xlx/papers/recsys14.pdf}
}

@article{xie04mmhard,
  author    = {Lexing Xie and Shamma, D.A. and Snoek, C.},
  journal   = {MultiMedia, IEEE},
  title     = {{Content is Dead ... Long Live Content: The New Age of Multimedia-Hard Problems}},
  year      = {2014},
  volume    = {21},
  number    = {1},
  pages     = {4-8},
  abstract  = {Using the ACM Multimedia 2012 panel on metadata as a jumping-off point, the authors investigate whether content can continue to play a dominant role in multimedia research in the age of social, local, and mobile media. In this article, they propose that the community now must face the challenge of characterizing the level of difficulty of multimedia problems to establish a better understanding of where content analysis needs further improvement. They also suggest a classification method that defines problem complexity in the context of human-assisted computation.},
  doi       = {10.1109/MMUL.2014.5},
  issn      = {1070-986X},
  month     = {Jan},
  url_paper = {http://users.cecs.anu.edu.au/~xlx/papers/mmhard_2014.pdf}
}

@article{Wang:2014:BCM:2656131.2611388,
  author     = {Wang, Zhiyu and Cui, Peng and Xie, Lexing and Zhu, Wenwu and Rui, Yong and Yang, Shiqiang},
  title      = {{Bilateral Correspondence Model for Words-and-Pictures Association in Multimedia-Rich Microblogs}},
  journal    = {ACM Trans. Multimedia Comput. Commun. Appl.},
  issue_date = {June 2014},
  volume     = {10},
  number     = {4},
  month      = jul,
  year       = {2014},
  issn       = {1551-6857},
  pages      = {34:1--34:21},
  articleno  = {34},
  numpages   = {21},
  url        = {http://doi.acm.org/10.1145/2611388},
  doi        = {10.1145/2611388},
  acmid      = {2611388},
  publisher  = {ACM},
  address    = {New York, NY, USA},
  keywords   = {Social media, image analysis, topic models},
  abstract   = {Nowadays, the amount of multimedia contents in microblogs is growing significantly. More than 20\% of microblogs link to a picture or video in certain large systems. The rich semantics in microblogs provides an opportunity to endow images with higher-level semantics beyond object labels. However, this raises new challenges for understanding the association between multimodal multimedia contents in multimedia-rich microblogs. Disobeying the fundamental assumptions of traditional annotation, tagging, and retrieval systems, pictures and words in multimedia-rich microblogs are loosely associated and a correspondence between pictures and words cannot be established. To address the aforementioned challenges, we present the first study analyzing and modeling the associations between multimodal contents in microblog streams, aiming to discover multimodal topics from microblogs by establishing correspondences between pictures and words in microblogs. We first use a data-driven approach to analyze the new characteristics of the words, pictures, and their association types in microblogs. We then propose a novel generative model called the Bilateral Correspondence Latent Dirichlet Allocation (BC-LDA) model. Our BC-LDA model can assign flexible associations between pictures and words and is able to not only allow picture-word co-occurrence with bilateral directions, but also single modal association. This flexible association can best fit the data distribution, so that the model can discover various types of joint topics and generate pictures and words with the topics accordingly. We evaluate this model extensively on a large-scale real multimedia-rich microblogs dataset. We demonstrate the advantages of the proposed model in several application scenarios, including image tagging, text illustration, and topic discovery. The experimental results demonstrate that our proposed model can significantly and consistently outperform traditional approaches.},
  url_paper  = {http://users.cecs.anu.edu.au/~xlx/papers/tomm-bclda.pdf}
}


@article{Liu:2014:SAI:2665935.2645643,
  author     = {Liu, Yong-Jin and Ma, Cui-Xia and Fu, Qiufang and Fu, Xiaolan and Qin, Sheng-Feng and Xie, Lexing},
  title      = {{A Sketch-Based Approach for Interactive Organization of Video Clips}},
  journal    = {ACM Trans. Multimedia Comput. Commun. Appl.},
  issue_date = {August 2014},
  volume     = {11},
  number     = {1},
  month      = sep,
  year       = {2014},
  issn       = {1551-6857},
  pages      = {2:1--2:21},
  articleno  = {2},
  numpages   = {21},
  url        = {http://doi.acm.org/10.1145/2645643},
  doi        = {10.1145/2645643},
  acmid      = {2645643},
  publisher  = {ACM},
  address    = {New York, NY, USA},
  keywords   = {Sketching interface, context-aware recommendation, sketch annotation, video organization},
  abstract   = {With the rapid growth of video resources, techniques for efficient organization of video clips are becoming appealing in the multimedia domain. In this article, a sketch-based approach is proposed to intuitively organize video clips by: (1) enhancing their narrations using sketch annotations and (2) structurizing the organization process by gesture-based free-form sketching on touch devices. There are two main contributions of this work. The first is a sketch graph, a novel representation for the narrative structure of video clips to facilitate content organization. The second is a method to perform context-aware sketch recommendation scalable to large video collections, enabling common users to easily organize sketch annotations. A prototype system integrating the proposed approach was evaluated on the basis of five different aspects concerning its performance and usability. Two sketch searching experiments showed that the proposed context-aware sketch recommendation outperforms, in terms of accuracy and scalability, two state-of-the-art sketch searching methods. Moreover, a user study showed that the sketch graph is consistently preferred over traditional representations such as keywords and keyframes. The second user study showed that the proposed approach is applicable in those scenarios where the video annotator and organizer were the same person. The third user study showed that, for video content organization, using sketch graph users took on average 1/3 less time than using a mass-market tool Movie Maker and took on average 1/4 less time than using a state-of-the-art sketch alternative. These results demonstrated that the proposed sketch graph approach is a promising video organization tool.},
  url_paper  = {http://users.cecs.anu.edu.au/~xlx/papers/TOMM14-sketch.pdf}
}

@inproceedings{Xie:2013:PTW:2502081.2502113,
  author     = {Xie, Lexing and He, Xuming},
  title      = {{Picture Tags and World Knowledge: Learning Tag Relations from Visual Semantic Sources}},
  booktitle  = {Proceedings of the 21st ACM International Conference on Multimedia},
  series     = {MM '13},
  year       = {2013},
  isbn       = {978-1-4503-2404-5},
  location   = {Barcelona, Spain},
  pages      = {967--976},
  numpages   = {10},
  url        = {http://doi.acm.org/10.1145/2502081.2502113},
  doi        = {10.1145/2502081.2502113},
  acmid      = {2502113},
  publisher  = {ACM},
  address    = {New York, NY, USA},
  keywords   = {folksonomy, knowledge graph, social media},
  abstract   = {This paper studies the use of everyday words to describe images. The common saying has it that 'a picture is worth a thousand words', here we ask which thousand? The proliferation of tagged social multimedia data presents a challenge to understanding collective tag-use at large scale -- one can ask if patterns from photo tags help understand tag-tag relations, and how it can be leveraged to improve visual search and recognition. We propose a new method to jointly analyze three distinct visual knowledge resources: Flickr, ImageNet/WordNet, and ConceptNet. This allows us to quantify the visual relevance of both tags learn their relationships. We propose a novel network estimation algorithm, Inverse Concept Rank, to infer incomplete tag relationships. We then design an algorithm for image annotation that takes into account both image and tag features. We analyze over 5 million photos with over 20,000 visual tags. The statistics from this collection leads to good results for image tagging, relationship estimation, and generalizing to unseen tags. This is a first step in analyzing picture tags and everyday semantic knowledge. Potential other applications include generating natural language descriptions of pictures, as well as validating and supplementing knowledge databases.},
  url_paper  = {http://cecs.anu.edu.au/~xlx/papers/mm2013-xie.pdf},
  url_slides = {http://cecs.anu.edu.au/~xlx/proj/tagnet/mm2013-tagnet.pdf},
  url_page   = {http://users.cecs.anu.edu.au/~xlx/proj/tagnet/}
}

@inproceedings{Sedhain:2013:SAF:2512938.2512947,
  author    = {Sedhain, Suvash and Sanner, Scott and Xie, Lexing and Kidd, Riley and Tran, Khoi-Nguyen and Christen, Peter},
  title     = {{Social Affinity Filtering: Recommendation Through Fine-grained Analysis of User Interactions and Activities}},
  booktitle = {Proceedings of the First ACM Conference on Online Social Networks},
  series    = {COSN '13},
  year      = {2013},
  isbn      = {978-1-4503-2084-9},
  location  = {Boston, Massachusetts, USA},
  pages     = {51--62},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/2512938.2512947},
  doi       = {10.1145/2512938.2512947},
  acmid     = {2512947},
  publisher = {ACM},
  address   = {New York, NY, USA},
  keywords  = {collaborative filtering, recommender systems, social networks},
  abstract  = {Content recommendation in social networks poses the complex problem of learning user preferences from a rich and complex set of interactions (e.g., likes, comments and tags for posts, photos and videos) and activities (e.g., favourites, group memberships, interests). While many social collaborative filtering approaches learn from aggregate statistics over this social information, we show that only a small subset of user interactions and activities are actually useful for social recommendation, hence learning which of these are most informative is of critical importance. To this end, we define a novel social collaborative filtering approach termed social affinity filtering (SAF). On a preference dataset of Facebook users and their interactions with 37,000+ friends collected over a four month period, SAF learns which fine-grained interactions and activities are informative and outperforms state-of-the-art (social) collaborative filtering methods by over 6\% in prediction accuracy; SAF also exhibits strong cold-start performance. In addition, we analyse various aspects of fine-grained social features and show (among many insights) that interactions on video content are more informative than other modalities (e.g., photos), the most informative activity groups tend to have small memberships, and features corresponding to “long-tailed” content (e.g., music and books) can be much more predictive than those with fewer choices (e.g., interests and sports). In summary, this work demonstrates the substantial predictive power of fine-grained social features and the novel method of SAF to leverage them for state-of-the-art social recommendation.},
  url_paper = {http://users.cecs.anu.edu.au/~xlx/papers/COSN2013.pdf}
}

@article{41769,
  title     = {{Tracking Large-Scale Video Remix in Real-World Events}},
  author    = {Lexing Xie and Apostol Natsev and Xuming He and John R. Kender and Matthew L. Hill and John R. Smith},
  year      = 2013,
  journal   = {IEEE Transactions on Multimedia},
  pages     = {1244-1254},
  volume    = {15, no. 6},
  doi       = {10.1109/TMM.2013.2264929},
  abstract  = {Content sharing networks, such as YouTube, contain traces of both explicit online interactions (such as likes, comments, or subscriptions), as well as latent interactions (such as quoting, or remixing, parts of a video). We propose visual memes, or frequently re-posted short video segments, for detecting and monitoring such latent video interactions at scale. Visual memes are extracted by scalable detection algorithms that we develop, with high accuracy. We further augment visual memes with text, via a statistical model of latent topics. We model content interactions on YouTube with visual memes, defining several measures of influence and building predictive models for meme popularity. Experiments are carried out with over 2 million video shots from more than 40,000 videos on two prominent news events in 2009: the election in Iran and the swine flu epidemic. In these two events, a high percentage of videos contain remixed content, and it is apparent that traditional news media and citizen journalists have different roles in disseminating remixed content. We perform two quantitative evaluations for annotating visual memes and predicting their popularity. The proposed joint statistical model of visual memes and words outperforms an alternative concurrence model, with an average error of 2\% for predicting meme volume and 17\% for predicting meme lifespan.},
  url_paper = {http://users.cecs.anu.edu.au/~xlx/papers/TMM-youtube.pdf}
}

@inproceedings{butt2013activeraul,
  title        = {{ActiveRaUL: A Web Form-based User Interface to Create and Maintain RDF Data}},
  author       = {Butt, Anila Sahar and Haller, Armin and Liu, Shepherd and Xie, Lexing},
  booktitle    = {Proceedings of the 2013th International Conference on Posters \& Demonstrations Track-Volume 1035},
  pages        = {117--120},
  year         = {2013},
  organization = {CEUR-WS. org},
  abstract     = {With the advent of Linked Data the amount of automatically generated machine-readable data on the Web, often obtained by means of mapping relational data to RDF, has risen significantly. However, manually created, quality-assured and crowd-sourced data based on ontologies is not available in the quantities that would realise the full potential of the semantic Web. One of the barriers for semantic Web novices to create machine-readable data, is the lack of easy-to-use Web publishing tools that separate the schema modelling from the data creation. In this demonstration we present ActiveRaUL, a Web service that supports the automatic generation of Web formbased user interfaces from any input ontology. The resulting Web forms are unique in supporting users, inexperienced in semantic Web technologies, to create and maintain RDF data modelled according to an ontology. We report on a use case based on the Sensor Network Ontology that supports the viability of our approach.},
  url_paper    = {http://ceur-ws.org/Vol-1035/iswc2013_demo_30.pdf}
}

@inproceedings{mehrotra2013improving,
  title        = {{Improving LDA Topic Models for Microblogs via Tweet Pooling and Automatic Labeling}},
  author       = {Mehrotra, Rishabh and Sanner, Scott and Buntine, Wray and Xie, Lexing},
  booktitle    = {Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval},
  pages        = {889--892},
  year         = {2013},
  organization = {ACM},
  abstract     = {Twitter, or the world of 140 characters poses serious challenges to the efficacy of topic models on short, messy text. While topic models such as Latent Dirichlet Allocation (LDA) have a long history of successful application to news articles and academic abstracts, they are often less coherent when applied to microblog content like Twitter. In this paper, we investigate methods to improve topics learned from Twitter content without modifying the basic machinery of LDA; we achieve this through various pooling schemes that aggregate tweets in a data preprocessing step for LDA. We empirically establish that a novel method of tweet pooling by hashtags leads to a vast improvement in a variety of measures for topic coherence across three diverse Twitter datasets in comparison to an unmodified LDA baseline and a variety of pooling schemes. An additional contribution of automatic hashtag labeling further improves on the hashtag pooling results for a subset of metrics. Overall, these two novel schemes lead to significantly improved LDA topic models on Twitter content.},
  url_paper    = {http://users.rsise.anu.edu.au/~ssanner/Papers/sigir13.pdf}
}

@article{wu2013scalable,
  title     = {{Scalable Mobile Video Retrieval with Sparse Projection Learning and Pseudo Label Mining}},
  author    = {Wu, Guan-Long and Kuo, Yin-Hsi and Chiu, Tzu-Hsuan and Hsu, Winston H and Xie, Lexing},
  journal   = {MultiMedia, IEEE},
  volume    = {20},
  number    = {3},
  pages     = {47--57},
  year      = {2013},
  publisher = {IEEE},
  abstract  = {Retrieving relevant videos from a large corpus on mobile devices is a vital challenge. This article addresses two key issues for mobile search on user-generated videos. The first is the lack of good relevance measurement for learning semantically rich representations, due to the unconstrained nature of online videos. The second is the limited resources on mobile devices, stringent bandwidth, and delay requirement between the device and video server. The authors propose a knowledge-embedded sparse projection learning approach. To alleviate the need for expensive annotation in hash learning, they investigate varying approaches for pseudo label mining, where explicit semantic analysis leverages Wikipedia. In addition, they propose a novel sparse projection method to address the efficiency challenge by learning a discriminative compact representation that drastically reduces transmission costs. With less than 10 percent nonzero elements in the projection matrix, it also reduces computational and storage costs. The experimental results on 100,000 videos show that the proposed algorithm yields performance competitive with the prior state-of-the-art hashing methods, which are not applicable for mobiles and solely rely on costly manual annotations. The average query time for 100,000 videos was only 0.592 seconds.},
  url_paper = {http://users.cecs.anu.edu.au/~xlx/papers/wu13scalable.pdf}
}

@article{liang2013optimal,
  title     = {{Optimal-Scaling-Factor Assignment for Patch-wise Image Retargeting}},
  author    = {Liang, Yun and Liu, Yong-Jin and Luo, Xiao-Nan and Xie, Lexing and Fu, Xiaolan},
  journal   = {Computer Graphics and Applications, IEEE},
  volume    = {33},
  number    = {5},
  pages     = {68--78},
  year      = {2013},
  publisher = {IEEE},
  abstract  = {Image retargeting adjusts images to arbitrary sizes such that they can be viewed on different displays. Content-aware image retargeting has been receiving increased attention. In particular, researchers have improved a patch-wise scaling method for image retargeting at the object level. The scaling partitions the image into rectangular patches of adaptive sizes, which are comparable to the sizes of the salient objects in the image. This partitioning is based on a visual-saliency map; accordingly, the method labels the patches as important or unimportant. Then, the method scales the important patches as uniformly as possible and stretches or squeezes the unimportant patches to fit the target size. A patch-based image-similarity measure finds the optimal set of scaling factors. In experiments, the improved method performed well for three image types: lines and edges, foreground objects, and geometric structures.},
  url_paper = {http://users.cecs.anu.edu.au/~xlx/papers/CGA-2013.pdf}
}

@article{ji2013learning,
  title     = {{Learning to Distribute Vocabulary Indexing for Scalable Visual Search}},
  author    = {Ji, Rongrong and Duan, Ling-Yu and Chen, Jie and Xie, Lexing and Yao, Hongxun and Gao, Wen},
  journal   = {Multimedia, IEEE Transactions on},
  volume    = {15},
  number    = {1},
  pages     = {153--166},
  year      = {2013},
  publisher = {IEEE},
  abstract  = {In recent years, there is an ever-increasing research focus on Bag-of-Words based near duplicate visual search paradigm with inverted indexing. One fundamental yet unexploited challenge is how to maintain the large indexing structures within a single server subject to its memory constraint, which is extremely hard to scale up to millions or even billions of images. In this paper, we propose to parallelize the near duplicate visual search architecture to index millions of images over multiple servers, including the distribution of both visual vocabulary and the corresponding indexing structure. We optimize the distribution of vocabulary indexing from a machine learning perspective, which provides a “memory light” search paradigm that leverages the computational power across multiple servers to reduce the search latency. Especially, our solution addresses two essential issues: “What to distribute” and “How to distribute”. “What to distribute” is addressed by a “lossy” vocabulary Boosting, which discards both frequent and indiscriminating words prior to distribution. “How to distribute” is addressed by learning an optimal distribution function, which maximizes the uniformity of assigning the words of a given query to multiple servers. We validate the distributed vocabulary indexing scheme in a real world location search system over 10 million landmark images. Comparing to the state-of-the-art alternatives of single-server search (5), (6), (16) and distributed search (23), our scheme has yielded a significant gain of about 200\% speedup at comparable precision by distributing only 5\% words. We also report excellent robustness even when partial servers crash.},
  url_paper = {http://cm.cecs.anu.edu.au/documents/ji2013learning.pdf}
}

@inproceedings{wang2012social,
  title        = {{Social Event Detection with Interaction Graph Modeling}},
  author       = {Wang, Yanxiang and Sundaram, Hari and Xie, Lexing},
  booktitle    = {Proceedings of the 20th ACM international conference on Multimedia},
  pages        = {865--868},
  year         = {2012},
  organization = {ACM},
  abstract     = {This paper focuses on detecting social, physical-world events from photos posted on social media sites. The problem is important: cheap media capture devices have significantly increased the number of photos shared on these sites. The main contribution of this paper is to incorporate online social interaction features in the detection of physical events. We believe that online social interaction reflect important signals among the participants on the "social affinity" of two photos, thereby helping event detection. We compute social affinity via a random-walk on a social interaction graph to determine similarity between two photos on the graph. We train a support vector machine classifier to combine the social affinity between photos and photo-centric metadata including time, location, tags and description. Incremental clustering is then used to group photos to event clusters. We have very good results on two large scale real-world datasets: Upcoming and MediaEval. We show an improvement between 0.06-0.10 in F1 on these datasets.},
  url_paper    = {http://arxiv.org/pdf/1208.2547v1.pdf}
}

@article{sundaram2012multimedia,
  title     = {{Multimedia Semantics: Interactions between Content and Community}},
  author    = {Sundaram, Hari and Xie, Lexing and De Choudhury, Munmun and Lin, Yu-Ru and Natsev, Apostol},
  journal   = {Proceedings of the IEEE},
  volume    = {100},
  number    = {9},
  pages     = {2737--2758},
  year      = {2012},
  publisher = {IEEE},
  abstract  = {This paper reviews the state of the art and some emerging issues in research areas related to pattern analysis and monitoring of web-based social communities. This research area is important for several reasons. First, the presence of near-ubiquitous low-cost computing and communication technologies has enabled people to access and share information at an unprecedented scale. The scale of the data necessitates new research for making sense of such content. Furthermore, popular websites with sophisticated media sharing and notification features allow users to stay in touch with friends and loved ones; these sites also help to form explicit and implicit social groups. These social groups are an important source of information to organize and to manage multimedia data. In this article, we study how media-rich social networks provide additional insight into familiar multimedia research problems, including tagging and video ranking. In particular, we advance the idea that the contextual and social aspects of media are as important for successful multimedia applications as is the media content. We examine the inter-relationship between content and social context through the prism of three key questions. First, how do we extract the context in which social interactions occur? Second, does social interaction provide value to the media object? Finally, how do social media facilitate the repurposing of shared content and engender cultural memes? We present three case studies to examine these questions in detail. In the first case study, we show how to discover structure latent in the social media data, and use the discovered structure to organize Flickr photo streams. In the second case study, we discuss how to determine the interestingness of conversations—and of participants—around videos uploaded to YouTube. Finally, we show how the analysis of visual content, in particular tracing of content remixes, can help us understand the relationship among YouTube p- rticipants. For each case, we present an overview of recent work and review the state of the art. We also discuss two emerging issues related to the analysis of social networks—robust data sampling and scalable data analysis.},
  url_paper = {http://users.cecs.anu.edu.au/~xlx/papers/pieee-2012.pdf}
}

@article{kavanaugh2012social,
  title     = {{Social Media Use by Government: From the Routine to The Critical}},
  author    = {Kavanaugh, Andrea L and Fox, Edward A and Sheetz, Steven D and Yang, Seungwon and Li, Lin Tzy and Shoemaker, Donald J and Natsev, Apostol and Xie, Lexing},
  journal   = {Government Information Quarterly},
  volume    = {29},
  number    = {4},
  pages     = {480--491},
  year      = {2012},
  publisher = {Elsevier},
  abstract  = {Social media and online services with user-generated content (e.g., Twitter, Facebook, Flickr, YouTube) have made a staggering amount of information (and misinformation) available. Government officials seek to leverage these resources to improve services and communication with citizens. Significant potential exists to identify issues in real time, so emergency managers can monitor and respond to issues concerning public safety. Yet, the sheer volume of social data streams generates substantial noise that must be filtered in order to detect meaningful patterns and trends. Important events can then be identified as spikes in activity, while event meaning and consequences can be deciphered by tracking changes in content and public sentiment. This paper presents findings from a exploratory study we conducted between June and December 2010 with government officials in Arlington, VA (and the greater National Capitol Region around Washington, D.C.), with the broad goal of understanding social media use by government officials as well as community organizations, businesses, and the public at large. A key objective was also to understand social media use specifically for managing crisis situations from the routine (e.g., traffic, weather crises) to the critical (e.g., earthquakes, floods).},
  url_paper = {http://users.cecs.anu.edu.au/~xlx/papers/GIQ2012.pdf}
}

@inproceedings{kim2012event,
  title     = {{Event Diffusion Patterns in Social Media}},
  author    = {Kim, Minkyoung and Xie, Lexing and Christen, Peter and others},
  booktitle = {ICWSM},
  year      = {2012},
  abstract  = {This study focuses on real-world events and their reflections on the continuous stream of online discussions. Studying event diffusion on social media is important, as this will tell us how a significant event (such as a natural disaster) spreads and evolves interacting with other events, and who has helped spreading the event. Tracking an ever-changing list of often unanticipated events is difficult, and most prior work has focused on specific event derivatives such as quotes or user-generated tags. In this paper, we propose a method for identifying real-world events on social media, and present observations about event diffusion patterns across diverse media types such as news, blogs, and social networking sites. We first construct an event registry based on the Wikipedia portal of global news events, and we represent each real-world event with entities that embody the 5W1H (e.g., organization, person name, place) used in news coverage. We then label each web document with the list of identified events based on entity similarity between them. We analyze the ICWSM’11 Spinn3r dataset containing over 60 million English documents. We observe surprising connections among the 161 events it covers, and that over half (55\%) of users only link to a small fraction of prolific users (4\%), a notable departure from the balanced traditional bow-tie model of web content.},
  url_paper = {http://users.cecs.anu.edu.au/~xlx/papers/icwsm12-event.pdf}
}

@inproceedings{xie2012media,
  title        = {{Media Lifecycle and Content Analysis in Social Media Communities}},
  author       = {Xie, Lexing and Sundaram, Hari},
  booktitle    = {Multimedia and Expo (ICME), 2012 IEEE International Conference on},
  pages        = {55--60},
  year         = {2012},
  organization = {IEEE},
  abstract     = {This paper examines the role of content analysis in media-rich online communities. We highlight changes in the multimedia generation and consumption process that has occurred the past decade, and discuss several new angles this has brought to multimedia analysis research. We first examine the content production, dissemination and consumption patterns in the recent social media studies literature. We then propose an updated conceptual summary of media lifecycle from a previous research column (6) by Chang. We present an update list of impact criteria and challenge areas for multimedia content analysis. Among the three criteria, two are existing but with new problems and solutions, one is new as a results of the communitydriven content lifecycle. We present three case studies that addresses the impact criteria, and conclude with an outlook for emerging problems.},
  url_paper    = {http://users.cecs.anu.edu.au/~xlx/papers/icme2012.pdf}
}

@inproceedings{noel2012new,
  title        = {{New Objective Functions for Social Collaborative Filtering}},
  author       = {Noel, Joseph and Sanner, Scott and Tran, Khoi-Nguyen and Christen, Peter and Xie, Lexing and Bonilla, Edwin V and Abbasnejad, Ehsan and Della Penna, Nicolas},
  booktitle    = {Proceedings of the 21st international conference on World Wide Web},
  pages        = {859--868},
  year         = {2012},
  organization = {ACM},
  abstract     = {This paper examines the problem of social collaborative filtering (CF) to recommend items of interest to users in a social network setting. Unlike standard CF algorithms using relatively simple user and item features, recommendation in social networks poses the more complex problem of learning user preferences from a rich and complex set of user profile and interaction information. Many existing social CF methods have extended traditional CF matrix factorization, but have overlooked important aspects germane to the social setting. We propose a unified framework for social CF matrix factorization by introducing novel objective functions for training. Our new objective functions have three key features that address main drawbacks of existing approaches: (a) we fully exploit feature-based user similarity, (b) we permit direct learning of user-to-user information diffusion, and (c) we leverage co-preference (dis)agreement between two users to learn restricted areas of common interest. We evaluate these new social CF objectives, comparing them to each other and to a variety of (social) CF baselines, and analyze user behavior on live user trials in a custom-developed Facebook App involving data collected over five months from over 100 App users and their 37,000+ friends.},
  url_paper    = {http://users.cecs.anu.edu.au/~xlx/papers/www12.pdf}
}

@article{tan2011imagehive,
  title     = {{ImageHive: Interactive Content-aware Image Summarization}},
  author    = {Tan, Li and Song, Yangqiu and Liu, Shixia and Xie, Lexing},
  journal   = {IEEE computer graphics and applications},
  number    = {1},
  pages     = {46--55},
  year      = {2011},
  publisher = {IEEE},
  abstract  = {ImageHive communicates information about an image collection by generating a summary image that preserves the relationships between images and avoids occluding their salient parts. It uses a constrained graph-layout algorithm first, to preserve image similarities and keep important parts visible, and then a constrained Voronoi tessellation algorithm to locally refine the layout and tile the image plane.},
  url_paper = {http://users.cecs.anu.edu.au/~xlx/papers/imagehive-cga.pdf}
}

@article{merler2012semantic,
  title     = {{Semantic Model Vectors for Complex Video Event Recognition}},
  author    = {Merler, Michele and Huang, Bert and Xie, Lexing and Hua, Gang and Natsev, Apostol},
  journal   = {Multimedia, IEEE Transactions on},
  volume    = {14},
  number    = {1},
  pages     = {88--101},
  year      = {2012},
  publisher = {IEEE},
  abstract  = {We propose semantic model vectors, an intermediate level semantic representation, as a basis for modeling and detecting complex events in unconstrained real-world videos, such as those from YouTube. The semantic model vectors are extracted using a set of discriminative semantic classifiers, each being an ensemble of SVM models trained from thousands of labeled web images, for a total of 280 generic concepts. Our study reveals that the proposed semantic model vectors representation outperforms-and is complementary to-other low-level visual descriptors for video event modeling. We hence present an end-to-end video event detection system, which combines semantic model vectors with other static or dynamic visual descriptors, extracted at the frame, segment, or full clip level. We perform a comprehensive empirical study on the 2010 TRECVID Multimedia Event Detection task (http://www.nist.gov/itl/iad/mig/med10.cfm), which validates the semantic model vectors representation not only as the best individual descriptor, outperforming state-of-the-art global and local static features as well as spatio-temporal HOG and HOF descriptors, but also as the most compact. We also study early and late feature fusion across the various approaches, leading to a 15\% performance boost and an overall system performance of 0.46 mean average precision. In order to promote further research in this direction, we made our semantic model vectors for the TRECVID MED 2010 set publicly available for the community to use (http://www1.cs.columbia.edu/~mmerler/SMV.html).},
  url_paper = {http://users.cecs.anu.edu.au/~xlx/papers/TMM-smv.pdf}
}

@article{lin2011scent,
  title     = {{SCENT: Scalable Compressed Monitoring of Evolving Multirelational Social Networks}},
  author    = {Lin, Yu-Ru and Candan, K Sel{\c{c}}cuk and Sundaram, Hari and Xie, Lexing},
  journal   = {ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)},
  volume    = {7},
  number    = {1},
  pages     = {29},
  year      = {2011},
  publisher = {ACM},
  abstract  = {We propose SCENT, an innovative, scalable spectral analysis framework for internet scale monitoring of multirelational social media data, encoded in the form of tensor streams. In particular, a significant challenge is to detect key changes in the social media data, which could reflect important events in the real world, sufficiently quickly. Social media data have three challenging characteristics. First, data sizes are enormous; recent technological advances allow hundreds of millions of users to create and share content within online social networks. Second, social data are often multifaceted (i.e., have many dimensions of potential interest, from the textual content to user metadata). Finally, the data is dynamic; structural changes can occur at multiple time scales and be localized to a subset of users. Consequently, a framework for extracting useful information from social media data needs to scale with data volume, and also with the number and diversity of the facets of the data. In SCENT, we focus on the computational cost of structural change detection in tensor streams. We extend compressed sensing (CS) to tensor data. We show that, through the use of randomized tensor ensembles, SCENT is able to encode the observed tensor streams in the form of compact descriptors. We show that the descriptors allow very fast detection of significant spectral changes in the tensor stream, which also reduce data collection, storage, and processing costs. Experiments over synthetic and real data show that SCENT is faster (17.7x--159x for change detection) and more accurate (above 0.9 F-score) than baseline methods.},
  url_paper = {http://users.cecs.anu.edu.au/~xlx/papers/lin2011scent.pdf}
}

@inproceedings{xie2011visual,
  title        = {{Visual Memes in Social Media: Tracking Real-world News in Youtube Videos}},
  author       = {Xie, Lexing and Natsev, Apostol and Kender, John R and Hill, Matthew and Smith, John R},
  booktitle    = {Proceedings of the 19th ACM international conference on Multimedia},
  pages        = {53--62},
  year         = {2011},
  organization = {ACM},
  abstract     = {We propose visual memes, or frequently reposted short video segments, for tracking large-scale video remix in social media. Visual memes are extracted by novel and highly scalable detection algorithms that we develop, with over 96\% precision and 80\% recall. We monitor real-world events on YouTube, and we model interactions using a graph model over memes, with people and content as nodes and meme postings as links. This allows us to define several measures of influence. These abstractions, using more than two million video shots from several large-scale event datasets, enable us to quantify and efficiently extract several important observations: over half of the videos contain re-mixed content, which appears rapidly; video view counts, particularly high ones, are poorly correlated with the virality of content; the influence of traditional news media versus citizen journalists varies from event to event; iconic single images of an event are easily extracted; and content that will have long lifespan can be predicted within a day after it first appears. Visual memes can be applied to a number of social media scenarios: brand monitoring, social buzz tracking, ranking content and users, among others.},
  url_paper    = {http://users.cecs.anu.edu.au/~xlx/papers/acmmm11-meme.pdf}
}

@inproceedings{dong2011detect,
  title        = {{Detect Irregularly Shaped Spatio-temporal Clusters for Decision Support (BEST PAPER AWARD)}},
  author       = {Dong, Weishan and Zhang, Xin and Jiang, Zhongbo and Sun, Wei and Xie, Lexing and Hampapur, Arun},
  booktitle    = {Service Operations, Logistics, and Informatics (SOLI), 2011 IEEE International Conference on},
  pages        = {231--236},
  year         = {2011},
  organization = {IEEE},
  abstract     = {Many real-world applications call for the use of detecting unusual clusters (abnormal phenomena or significant change) from spatio-temporal data for decision support, e.g., in disease surveillance systems and crime monitoring systems. More accurate detection can offer stronger decision support to enable more effective early warning and efficient resource allocation. Many spatial/spatio-temporal clustering approaches have been designed to detect significantly unusual clusters for decision support. In this paper, we focus on more accurately detecting irregularly shaped unusual clusters for point processes and propose a novel approach named EvoGridStatistic. The original problem is mathematically converted to an optimization problem and solved by estimation of distribution algorithm (EDA), which is a powerful global optimization tool. We also propose a prospective spatio-temporal cluster detection approach for surveillance purposes, named EvoGridStatistic-Pro. Experiments verify the effectiveness and efficiency of EvoGridStatistic-Pro over previous approaches. The scalability of our approach is also significantly better than previous ones, which enables EvoGridStatistic-Pro to apply to very large data sets in real-world application systems.},
  url_paper    = {http://cm.cecs.anu.edu.au/documents/dong2011detect.pdf}
}

@article{kavanaugh2012social,
  title     = {{Social Media Use by Government: From the Routine to The Critical}},
  author    = {Kavanaugh, Andrea L and Fox, Edward A and Sheetz, Steven D and Yang, Seungwon and Li, Lin Tzy and Shoemaker, Donald J and Natsev, Apostol and Xie, Lexing},
  journal   = {Government Information Quarterly},
  volume    = {29},
  number    = {4},
  pages     = {480--491},
  year      = {2012},
  publisher = {Elsevier},
  abstract  = {Social media (i.e., Twitter, Facebook, Flickr, YouTube) and other services with user-generated content have made a staggering amount of information (and misinformation) available. Government officials seek to leverage these resources to improve services and communication with citizens. Yet, the sheer volume of social data streams generates substantial noise that must be filtered. Nonetheless, potential exists to identify issues in real time, such that emergency management can monitor and respond to issues concerning public safety. By detecting meaningful patterns and trends in the stream of messages and information flow, events can be identified as spikes in activity, while meaning can be deciphered through changes in content. This paper presents findings from a pilot study we conducted between June and December 2010 with government officials in Arlington, Virginia (and the greater National Capitol Region around Washington, DC) with a view to understanding the use of social media by government officials as well as community organizations, businesses and the public. We are especially interested in understanding social media use in crisis situations (whether severe or fairly common, such as traffic or weather crises).},
  url_paper = {http://www.ctrnet.net/sites/default/files/dgo.2011.Paper\%20Final.pdf}
}

@inproceedings{xie2011tracking,
  title     = {{Tracking Visual Memes in Rich-Media Social Communities}},
  author    = {Xie, Lexing and Natsev, Apostol and Kender, John R and Hill, Matthew L and Smith, John R and others},
  booktitle = {ICWSM},
  year      = {2011},
  abstract  = {We propose tools and methods to track visual memes on community-centric rich-media repositories, such as YouTube. Visual memes refer to frequently reposted short video segments. Our method can be used to monitor the reflections of real-world events in rich media, including images and videos. We first design a large-scale event-based social video collection system to continuously monitor events that unfold in real-time. We design a scalable detection algorithms that can detect visual memes with over 96\% precision and 80\% recall. Visual memes are used for various analysis such as tracking the fraction of original content, extracting the iconic picture of an event, inferring influential users in the community, and so on. We present example observations on several real-world video collections from YouTube, containing up to 1.2 million video shots, including a compact taxonomy of authors into “traditional news media”, “citizen buzz leaders”, and “mavens”.},
  url_paper = {http://www.aaai.org/ocs/index.php/ICWSM/ICWSM11/paper/view/2789/3216}
}

@article{hampapur2011analytics,
  title     = {{Analytics-driven Asset Management}},
  author    = {A. {Hampapur} and H. {Cao} and A. {Davenport} and W. S. {Dong} and D. {Fenhagen} and R. S. {Feris} and G. {Goldszmidt} and Z. B. {Jiang} and J. {Kalagnanam} and T. {Kumar} and H. {Li} and X. {Liu} and S. {Mahatma} and S. {Pankanti} and D. {Pelleg} and W. {Sun} and M. {Taylor} and C. H. {Tian} and S. {Wasserkrug} and L. {Xie} and M. {Lodhi} and C. {Kiely} and K. {Butturff} and L. {Desjardins}},
  journal   = {IBM Journal of Research and Development},
  volume    = {55},
  number    = {1.2},
  pages     = {13--1},
  year      = {2011},
  publisher = {IBM},
  abstract  = {Asset-intensive businesses across industries rely on physical assets to deliver services to their customers, and effective asset management is critical to the businesses. Today, businesses may make use of enterprise asset-management (EAM) solutions for many asset-related processes, ranging from the core asset-management functions to maintenance, inventory, contracts, warranties, procurement, and customer-service management. While EAM solutions have transformed the operational aspects of asset management through data capture and process automation, the decision-making process with respect to assets still heavily relies on institutional knowledge and anecdotal insights. Analytics-driven asset management is an approach that makes use of advanced analytics and optimization technologies to transform the vast amounts of data from asset management, metering, and sensor systems into actionable insight, foresight, and prescriptions that can guide decisions involving strategic and tactical assets, as well as customer and business models.},
  url_paper = {http://dl.acm.org/citation.cfm?id=2001054}
}

@inproceedings{xie2010probabilistic,
  title        = {{Probabilistic Visual Concept Trees}},
  author       = {Xie, Lexing and Yan, Rong and Te{\v{s}}i{\'c}, Jelena and Natsev, Apostol and Smith, John R},
  booktitle    = {Proceedings of the 18th ACM international conference on Multimedia},
  pages        = {867--870},
  year         = {2010},
  organization = {ACM},
  abstract     = {This paper presents probabilistic visual concept trees, a model for large visual semantic taxonomy structures and its use in visual concept detection. Organizing visual semantic knowledge systematically is one of the key challenges towards large-scale concept detection, and one that is complementary to optimizing visual classification for individual concepts. Semantic concepts have traditionally been treated as isolated nodes, a densely-connected web, or a tree. Our analysis shows that none of these models are sufficient in modeling the typical relationships on a real-world visual taxonomy, and these relationships belong to three broad categories -- semantic, appearance and statistics. We propose probabilistic visual concept trees for modeling a taxonomy forest with observation uncertainty. As a Bayesian network with parameter constraints, this model is flexible enough to account for the key assumptions in all three types of taxonomy relations, yet it is robust enough to accommodate expansion or deletion in a taxonomy. Our evaluation results on a large web image dataset show that the classification accuracy has considerably improved upon baselines without, or with only a subset of concept relationships.},
  url_paper    = {http://users.cecs.anu.edu.au/~xlx/papers/visualtree-acmmm10.pdf}
}

@inproceedings{kender2010video,
  title        = {{Video Genetics: a Case Study from Youtube}},
  author       = {Kender, John R and Hill, Matthew L and Natsev, Apostol Paul and Smith, John R and Xie, Lexing},
  booktitle    = {Proceedings of the 18th ACM international conference on Multimedia},
  pages        = {1253--1258},
  year         = {2010},
  organization = {ACM},
  abstract     = {We explore in a single but large case study how videos within YouTube, competing for view counts, are like organisms within an ecology, competing for survival. We develop this analogy, whose core idea shows that short video clips, best detected across videos as near-duplicate keyframes, behave similarly to genes. We report work in progress, on a dataset of 5.4K videos with 210K keyframes on a single topic, which traces sequences, not bags, of “near-dups” over time, both within videos and across them. We demonstrate their utility to: cleanse responses to queries contaminated by over-eager YouTube query expansion; separate videos temporally according to their responses to external events; track the evolution and lifespan of continuing video “stories”; automatically locate video summaries already present within a video ecology; quickly verify video copying via a direct application of the Smith Waterman algorithm used in genetics—which also provides useful feedback for tuning the near-dup detection and clustering process; and quickly classify videos via a kind of Lempel-Ziv encoding into the categories of news, monologue, dialogue, and slideshow. We demonstrate a number of novel visualizations of this large dataset, including a direct use of the Matlab black-body “hot” false-color map, together with the GraphViz package, to display the gene-like inheritance of viral properties of keyframes. We further speculate that, as with genes, there are “functional roles” for semantic categories of clips, and, as with species, there are differings rates of “genetic drift” for each video genre.},
  url_paper    = {http://users.cecs.anu.edu.au/~xlx/papers/videogenetics-acmmm10.pdf}
}

@inproceedings{xie2010accuracy,
  title        = {{The Accuracy and Value of Machine-generated Image Tags: Design and User Evaluation of an End-to-end Image Tagging System}},
  author       = {Xie, Lexing and Natsev, Apostol and Hill, Matthew and Smith, John R and Phillips, Alex},
  booktitle    = {Proceedings of the ACM International Conference on Image and Video Retrieval},
  pages        = {58--65},
  year         = {2010},
  organization = {ACM},
  abstract     = {Automated image tagging is a problem of great interest, due to the proliferation of photo sharing services. Researchers have achieved considerable advances in understanding motivations and usage of tags, recognizing relevant tags from image content, and leveraging community input to recommend more tags. In this work we address several important issues in building an end-to-end image tagging application, including tagging vocabulary design, taxonomy-based tag refinement, classifier score calibration for effective tag ranking, and selection of valuable tags, rather than just accurate ones. We surveyed users to quantify tag utility and error tolerance, and use this data in both calibrating scores from automatic classifiers and in taxonomy based tag expansion. We also compute the relative importance among tags based on user input and statistics from Flickr. We present an end-to-end system evaluated on thousands of user-contributed photos using 60 popular tags. We can issue four tags per image with over 80\% accuracy, up from 50\% baseline performance, and we confirm through a comparative user study that value-ranked tags are preferable to accuracy-ranked tags.},
  url_paper    = {http://users.cecs.anu.edu.au/~xlx/papers/civr2010.pdf}
}

@article{de2010does,
  title     = {{How does The Data Sampling Strategy Impact the Discovery of Information Diffusion in Social Media?}},
  author    = {De Choudhury, Munmun and Lin, Yu-Ru and Sundaram, Hari and Candan, K Selcuk and Xie, Lexing and Kelliher, Aisling and others},
  journal   = {ICWSM},
  volume    = {10},
  pages     = {34--41},
  year      = {2010},
  abstract  = {Platforms such as Twitter have provided researchers with ample opportunities to analytically study social phenomena. There are however, significant computational challenges due to the enormous rate of production of new information: researchers are therefore, often forced to analyze a judiciously selected “sample” of the data. Like other social media phenomena, information diffusion is a social process–it is affected by user context, and topic, in addition to the graph topology. This paper studies the impact of different attribute and topology based sampling strategies on the discovery of an important social media phenomena–information diffusion. We examine several widely-adopted sampling methods that select nodes based on attribute (random, location, and activity) and topology (forest fire) as well as study the impact of attribute based seed selection on topology based sampling. Then we develop a series of metrics for evaluating the quality of the sample, based on user activity (e.g. volume, number of seeds), topological (e.g. reach, spread) and temporal characteristics (e.g. rate). We additionally correlate the diffusion volume metric with two external variables–search and news trends. Our experiments reveal that for small sample sizes (30\%), a sample that incorporates both topology and user context (e.g. location, activity) can improve on naive methods by a significant margin of ~15-20\%.},
  url_paper = {http://www.aaai.org/ocs/index.php/ICWSM/ICWSM10/paper/view/1521/1832}
}

